{"id": "1001428", "question": "adaboost里的learning rate是什么意思？", "description": "<div class=\"col-md-11 col-xs-10\"><p>adaboost和gradient boost不同的地方在于，adaboost不需要求梯度。那么adaboost模型为什么还会有learning rate？</p><p>非常困惑，谢谢解答！</p><p><br/></p></div>", "viewer": 6045, "tags": ["统计/机器学习", "监督式学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>adaboost没有用到梯度下降，adaboost中的learning rate也不是步长，这里的学习率只是指的每个树的权重的衰减速度。adaboost会逐一产生很多随机的决策树，每棵树的权重不同，learning rate就是权重衰减的速率。</p><p><br/></p><p>sklearn文档的官方说法是</p><p><span style=\"color: rgb(57, 123, 33);\">learning_rate : float, optional (default=1.)</span></p><p><span style=\"color: rgb(57, 123, 33);\">Learning rate shrinks the contribution of each classifier by learning_rate. </span></p><p><span style=\"color: rgb(57, 123, 33);\"><br/></span></p></div>", "lvl2_answer": []}]}