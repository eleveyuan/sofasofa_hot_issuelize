{"id": "1000909", "question": "Adam优化算法", "description": "<div class=\"col-md-11 col-xs-10\"><p>有了解ADAM这种优化算法的吗？在Keras一些nerual net的包里经常是用Adam方法作为默认solver。我大概知道Adam算是SGD的一种改良。但是我也是一知半解的，不是非常清楚它具体是怎么一回事，又是如何改良SGD的。</p><p>求懂adam的大神解答一下！</p><p>谢谢！（教师节快乐^_^)</p><p><br/></p></div>", "viewer": 6183, "tags": ["数学", "数值计算", "最优化"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">Adam(Adaptive Moment Estimation)本质上是带有动量项的RMSprop，它利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。Adam的优点主要在于经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。</span><br/></p><p><br/><span style=\"font-size: 14px;\">特点：\n</span></p><ol><li><span style=\"font-size: 14px;\">结合了Adagrad善于处理稀疏梯度和RMSprop善于处理非平稳目标的优点 </span></li><li><span style=\"font-size: 14px;\">对内存需求较小\n</span></li><li><span style=\"font-size: 14px;\">为不同的参数计算不同的自适应学习率\n</span></li><li><span style=\"font-size: 14px;\">也适用于大多非凸优化 - 适用于大数据集和高维空间</span></li></ol></div>", "lvl2_answer": []}]}