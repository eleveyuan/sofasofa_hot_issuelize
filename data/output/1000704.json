{"id": "1000704", "question": "Tensorflow多层神经网络训练最后输出的值都一样的，找不到是什么原因？", "description": "<div class=\"col-md-11 col-xs-10\"><p>我tensorflow建立6层全连接神经网络，网络的输入数据2625 个，输出数据1个。理想情况下输出数据应该按照一定规<span style=\"font-size: 1rem;\">规律随着输入数据的变化而变化的，但是训练到最后，无论输入数据是多，输出数据都是一个数值，loss在来回跳动，</span><span style=\"font-size: 1rem;\">没有减小。</span></p><p>我的模型代码如下：</p><pre><code class=\"python\">import sys\nsys.path.insert(0, '/home/wcsmomo/workspace/tutorials')\n#from __future__ import print_function, division\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nfrom my_ant_v3 import FetchDataSets as fds\nimport DBUtil as dbu\nfrom my_ant_v3 import ant_loger\n\nclass Network():\n    def __init__(self, num_hidden, num_hidden_2, num_hidden_3, num_hidden_4 , num_hidden_5, batch_size ):\n        self.batch_size = batch_size\n        self.test_batch_size = batch_size\n        # Hyper Parameters\n        self.num_hidden = num_hidden\n        self.num_hidden_2 = num_hidden_2\n        self.num_hidden_3 = num_hidden_3\n        self.num_hidden_4 = num_hidden_4\n        self.num_hidden_5 = num_hidden_5\n        # Graph Related\n        self.graph = tf.Graph()\n        self.tf_train_samples = None\n        self.tf_train_labels = None\n        self.tf_test_samples = None\n        self.tf_test_labels = None\n        self.tf_test_prediction = None\n\n    def define_graph(self):\n        with self.graph.as_default():\n            self.tf_train_samples = tf.placeholder(tf.float32, shape=(self.batch_size, 375*7))\n            self.tf_train_labels = tf.placeholder(tf.float32, shape=(self.batch_size, 1))\n            self.tf_test_samples = tf.placeholder(tf.float32, shape=(self.test_batch_size, 375*7))\n            self.tf_test_labels = tf.placeholder(tf.float32, shape=(self.test_batch_size, 1))\n\n   # fully connected layer 1, fully connected\n\n   fc1_weights = tf.Variable(tf.truncated_normal([375*7, self.num_hidden], stddev=0.1))\n\n   fc1_biases = tf.Variable(tf.constant(0.0, shape=[self.num_hidden]))\n\n\n\n   # fully connected layer 2\n\n   fc2_weights = tf.Variable(tf.truncated_normal([self.num_hidden, self.num_hidden_2], stddev=0.1))\n\n   fc2_biases = tf.Variable(tf.constant(0.0, shape=[self.num_hidden_2]))\n\n\n\n   # fully connected layer 3\n\n   fc3_weights = tf.Variable(tf.truncated_normal([self.num_hidden_2, self.num_hidden_3], stddev=0.1))\n\n   fc3_biases = tf.Variable(tf.constant(0.0, shape=[self.num_hidden_3]))\n\n\n\n   # fully connected layer 4\n\n   fc4_weights = tf.Variable(tf.truncated_normal([self.num_hidden_3, self.num_hidden_4], stddev=0.1))\n\n   fc4_biases = tf.Variable(tf.constant(0.0, shape=[self.num_hidden_4]))\n\n\n\n   # fully connected layer 5\n\n   fc5_weights = tf.Variable(tf.truncated_normal([self.num_hidden_4, self.num_hidden_5], stddev=0.1))\n\n   fc5_biases = tf.Variable(tf.constant(0.0, shape=[self.num_hidden_5]))\n\n\n\n   # fully connected layer 6 --&gt; output layer\n\n   fc6_weights = tf.Variable(tf.truncated_normal([self.num_hidden_5, 1], stddev=0.0))\n\n   fc6_biases = tf.Variable(tf.constant(0.0, shape=[1]))\n\n\n   def model(input_data):\n    hidden = tf.nn.relu(tf.matmul(input_data, fc1_weights) + fc1_biases)\n    hidden = tf.nn.dropout(hidden, 0.75)\n\n    # fully connected layer 2\n    hidden_2 = tf.nn.relu(tf.matmul(hidden, fc2_weights) + fc2_biases)\n    hidden_2 = tf.nn.dropout(hidden_2, 0.75\n\n    # fully connected layer 3\n    hidden_3 = tf.nn.relu(tf.matmul(hidden_2, fc3_weights) + fc3_biases)\n    hidden_3 = tf.nn.dropout(hidden_3, 0.75)\n\n    # fully connected layer 4\n    hidden_4 = tf.nn.relu(tf.matmul(hidden_3, fc4_weights) + fc4_biases)\n    hidden_4 = tf.nn.dropout(hidden_4, 0.75)\n\n    # fully connected layer 5\n    hidden_5 = tf.nn.relu(tf.matmul(hidden_4, fc5_weights) + fc5_biases)\n    \n    return tf.matmul(hidden_5, fc6_weights) + fc6_biases\n\n   # Training computation.\n   self.logits = model(self.tf_train_samples)\n   self.loss = tf.reduce_mean(tf.squared_difference(self.logits, self.tf_train_labels))\n\n   # Optimizer.\n   #self.optimizer = tf.train.RMSPropOptimizer(0.00005).minimize(self.loss)\n   #self.optimizer = tf.train.AdadeltaOptimizer(0.00005).minimize(self.loss)\n\n   self.optimizer = tf.train.AdagradOptimizer(0.00001).minimize(self.loss)\n   #self.optimizer = tf.train.AdamOptimizer(0.00005).minimize(self.loss)\n\n   # Predictions for the training, validation, and test\n   self.test_prediction = model(self.tf_test_samples)\n\n def run(self):\n  loger = ant_loger.Loger(\"/home/wcsmomo/workspace/tutorials/ant.log\")\n  self.session = tf.Session(graph=self.graph)\n  with self.session as session:\n   session.run(tf.global_variables_initializer())\n   saver = tf.train.Saver()\n   i = 0\n   count = 0\n   ck = fds.CreateKindleLines(self.batch_size, data_type='train')\n   test_ck = fds.CreateKindleLines(self.test_batch_size, data_type='test')\n   while i &lt; ck.avg_k_count:\n    if i == ck.avg_k_count -1 :\n     i = 0\n     ck.k = 0\n     test_ck.k = 0\n    i +=1\n    count +=1\n    bat_x,bat_y = ck.fetch_batch_slope_continue_time()\n\n    bat_x = np.reshape(bat_x , [self.batch_size,2625])\n    bat_y = np.reshape(bat_y, [self.batch_size, 1])\n    logits = session.run(self.logits , feed_dict={self.tf_train_samples:bat_x, self.tf_train_labels:bat_y})\n    #print(logits)\n    _, los = session.run([self.optimizer, self.loss], feed_dict = {self.tf_train_samples:bat_x, self.tf_train_labels:bat_y})\n\n    if i % 10 == 0:\n     test_bat_x, test_bat_y = test_ck.fetch_batch_slope_continue_time()\n     test_bat_x = np.reshape(test_bat_x, [self.test_batch_size, 2625])\n     test_bat_y = np.reshape(test_bat_y, [self.test_batch_size, 1])\n     pred = session.run(self.test_prediction,\n        feed_dict={self.tf_test_samples:test_bat_x, self.tf_test_labels:test_bat_y})\n     #accuracy = self.accuracy(pred, test_bat_y, True);\n     loger.info(\"bat_y: \"+str(bat_y))\n     loger.info(\"pred: \"+str(pred))\n     print(bat_y)\n     print(pred)\n     print('Minibatch loss at step %d lost: %f' % (i, los))\n\n     #print('Minibatch accuracy: %.1f%%' % accuracy[0])\n    if count % 100 == 0 and self.is_save():\n     path = '/home/wcsmomo/workspace/MultLayerNet.ckpt'\n     save_path = saver.save(self.session, path)\n     print(\"save_path:\" , save_path)\n\n def accuracy(self, predictions, labels, need_confusion_matrix=False):\n  '''\n  @return: accuracy and confusionMatrix as a tuple\n  '''\n\n  _predictions = np.argmax(predictions, 1)\n  _labels = np.argmax(labels, 1)\n\n  cm = confusion_matrix(_labels, _predictions) if need_confusion_matrix else None\n  # == is overloaded for numpy array\n  accuracy = (100.0 * np.sum(_predictions == _labels) / predictions.shape[0])\n  return accuracy, cm\n\n def is_save(self):\n  conn = dbu.Conn().get_conn()\n  sql = \"select value from ba_site where key_name='IS_SAVE'\n  cur = conn.cursor()\n  cur.execute(sql)\n  results = cur.fetchall()\n  flg = results[0][0]\n  flg_bl = flg == 'Y'\n  return flg_bl\n\nif __name__ == '__main__':\n net = Network(num_hidden=3000 , num_hidden_2=1000,\n      num_hidden_3=500, num_hidden_4=200, num_hidden_5=50,\n      batch_size=100)\n net.define_graph()\n net.run()\n</code></pre><p><br/></p><p><br/></p></div>", "viewer": 13606, "tags": ["统计/机器学习", "深度学习", "Python", "人工神经网络", "TensorFlow"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>遇到了这个问题，我的loss值最开始是在比较大的值上一直无法收敛，查看网络权值梯度，最开始的梯度返回已经是e-3级别了，因此网络基本没调整。</p><p>目前知道的方法有：</p><p>初始化不对，查看每层网络的输入方差，如果方差越来越小，可以判定为初始化不对，而你的初始化也是采用的基本的高斯函数，有很大可能是初始化的问题；</p><p>采用BN（批量标准化），可以稍微降低初始化对网络的影响；</p><p>如果你有更好的办法，求告知。</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>好长好长的code。我没有逐行看，但是有几个可能性：</p><p>1、你的预测输出标签，而不是概率。如果你的数据是非常倾斜，1:20什么的，基本上不管怎么预测，预测标签都会是0。</p><p>2、你的bias项一直都是0，tf.Variable(tf.constant(0.0, shape=[self.num_hidden]))。这也许是一个可能。</p><p>3、你的模型层数比较多，激活函数都是一样的。可以试试两层、三层的，效果如何。也可以换个激活函数试试。</p><p><br/></p></div>", "lvl2_answer": ["我输出的确是值，不是概率。我处理的不是分类问题，我输出的值是连续的。这样的话，不能这么处理吗?", "因为我输出的结果是在零的左右分布的，所以我把bias设置为0了，这样能从一个比较好的起点开始训练，如果不是0的话，loss会从很大的数慢慢下降。", "不行的，bias是1，如果是0，模型会自动把bias的权重训练为0。如果你处理的不是分类问题，里面不该出现confusion matrix和logit function之类的代码。", "我把网络变成了3层,并且降低了隐藏层的神经元个数，发现loss在随机跳动，似乎没有学到任何特征，应该是神经网络层数低了导致网络的学习能力不足。", "sorry , def accuracy(self, predictions, labels, need_confusion_matrix=False) 这个函数是一个废弃的，没有被调用的函数。logits 也仅仅用于表示输层的输出结果而已。", "bias换成1了吗？试了其他激活函数吗？你的激活函数全是relu，relu无法输出负数吧，你的真实值都是正数？", "还有个情况就是，最开始我设置bias = 0.1 ,然后训练到最后所有的输出值也全是一个。", "把bias换成1了，激活函数去掉了，直接输出y=w*x+b的值，还是一样的情况，我现在有点怀疑，是不是batch_size设置为100导致每次更新误差是按这次训练的误差均值去更新权重的。所以它就学习不到更细节的特征，导致它输出的结果都是接近的值。", "您好，请问您的问题解决了么，我也遇到了类似的问题"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>这可能是没有对数据进行正则化导致的，在很简单的模型上能重现类似的问题。</p></div>", "lvl2_answer": []}]}