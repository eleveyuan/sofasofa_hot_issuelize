{"id": "1000889", "question": "决策树模型有什么特点以及如何防止过拟合？", "description": "<div class=\"col-md-11 col-xs-10\"><p>如题</p></div>", "viewer": 9216, "tags": ["统计/机器学习", "监督式学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">决策树模型有以下几个特点。</span></p><ol><li><span style=\"font-size: 14px;\">训练过程比较简单，也就是在实际使用中比较好实现。</span></li><li><span style=\"font-size: 14px;\">在对一个新的样本进行预测时，时间复杂度是 O(k)，这个k是树的深度，也就是树有多少层。因此决策树的预测过程的非常快速而简单。</span></li><li><span style=\"font-size: 14px;\">决策树在训练过程中也能算出每个特征（feature）的重要程度。</span></li><li><span style=\"font-size: 14px;\">想比于其它分类算法，比如SVM和逻辑回归，决策树更能简单地应用到多元分类的问题上。</span></li><li><span style=\"font-size: 14px;\">如不加限制，决策树模型很容易出现过拟合(overfitting)。</span></li></ol><p><span style=\"font-size: 14px;\">针对决策树模型容易过拟合的特点，目前常见的有以下几个性质来进行控制。</span></p><ol><li><span style=\"font-size: 14px;\">树的深度，也就是树有多少层。</span></li><li><span style=\"font-size: 14px;\">一个节点能被继续拆分出子节点所需要的包含最少的样本个数。</span></li><li><span style=\"font-size: 14px;\">最底层节点所需要包含的最少样本个数。</span></li></ol><p><span style=\"font-size: 14px;\">以上三个决策树都相当于它的超参数(hyper-parameter), 也就是我们在训练过程中需要去调整的。但是如果采用随机森林模型，它能够已集成(ensemble) 的方法解决过拟合的问题，因此可以作为实际应用的决策树的很好的替代算法。</span></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>决策树可以通过<a href=\"http://sofasofa.io/forum_main_post.php?postid=1000336\" target=\"_blank\">剪枝</a>来避免过拟合。</p><p>或者也可以随机生成很多决策树（也就是TreeBagging或者随机森林），这样也能防止过拟合。（<a href=\"http://sofasofa.io/forum_main_post.php?postid=1000303\" target=\"_blank\">随机森林会发生过拟合吗？</a>）</p><p><br/></p></div>", "lvl2_answer": []}]}