{"id": "1003358", "question": "Ridge回归的解析解是什么？", "description": "<div class=\"col-md-11 col-xs-10\"><p><span style=\"font-size: 1rem;\">如果没有正则项，那么矩阵解为</span><br/></p><p>$$\\hat{\\beta}=(X^TX)^{−1}X^Ty$$</p><p>如果加了$L_2$正则项，那么Ridge回归的解析解是什么？</p></div>", "viewer": 4771, "tags": ["统计/机器学习", "回归分析"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>这个可以根据岭回归的损失函数推导的，</p><p>$$Loss(\\beta)=(Y-X\\beta)^T(Y-X\\beta)+\\lambda \\beta^T\\beta$$</p><p>$\\lambda$是正则项的系数</p><p>这个是凸问题，所以导数为0时取得解</p><p>$$\\frac{\\partial Loss}{\\partial \\beta}=2X^TX\\beta-2X^TY+2\\lambda I\\beta=0$$</p><p>所以</p><p>$$(X^TX+\\lambda I)\\beta=X^TY$$</p><p>解析解为</p><p>$$\\beta=(X^TX+\\lambda I)^{-1}X^TY$$</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>Ridge是有解析解的，假如正则项的惩罚系数为$\\lambda$，那么解析为</p><p>$$\\hat{\\beta}=(X^TX+\\lambda I)^{−1}X^Ty$$</p><p>里面的$I$是单位矩阵</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>LASSO没有一步到位的解析解。</p><p>$$l(\\beta)=(X\\beta-y)^T(X\\beta-y)+\\lambda|\\beta|_1$$</p><p>$$\\frac{\\partial l}{\\partial \\beta}=X^T(X\\beta-y)+\\lambda sign(\\beta)=0$$</p><p>$$\\beta=(X^TX+\\lambda sign(.))^{-1}X^Ty$$</p><p>因为右面和当前估计值$sign(\\beta)$有关，只能用迭代的方法求出。不过求矩阵逆的计算量很大，还不如用gradient descent类方法。</p><p>---------------</p><p>不好意思，看成LASSO的了。Ridge的解析解应该是strong.man写的。</p></div>", "lvl2_answer": []}]}