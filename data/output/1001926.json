{"id": "1001926", "question": "在线性回归模型中存在epoch的说法吗？", "description": "<div class=\"col-md-11 col-xs-10\"><p>之前是在神经网络里面听说一个epoch，是对整个训练集过一遍。今天在一本书的线性回归的梯度下降部分，也看到了一个RMSE随着epoch的增加而减小的图，那么问题来了“为什么每经历一个epoch，rmse都会减小呢？”</p></div>", "viewer": 4703, "tags": ["统计/机器学习", "回归分析"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>你看到的这个“epoch”不是针对的回归模型，而是针对的随机梯度下降算法的。</p><p>算法要收敛到最优，RMSE当然会不当下降。</p><p>推荐阅读下<a href=\"http://sofasofa.io/tutorials/python_gradient_descent/\" target=\"_blank\">自己动手用python写梯度下降</a></p><p><br/></p></div>", "lvl2_answer": ["恩恩 谢谢，我理解了rmse可能会随着过拟合不当下降，那么为什么要过很多个epoch呢？而且为什么每个epoch后rmse都会减小？", "因为训练一次之后，很可能模型还不够好（欠拟合）"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>这是把rmse作为loss/cost function，并且learning rate足够小，才能使training rmse逐渐下降。但是testing rmse在达到overfitting后会上升。还有当loss function中加入一些prior/regularization项时，training rmse也会到达拐点后上升。</p></div>", "lvl2_answer": ["请问testing rmse在什么时候计算呢？模型中的参数每更新一次，就计算一次testing rmse？", "有时把training data分一部分作validation data，或者作cross validation。想法就是把一部分training 暂时作为testing。", "rmse是convex function，肯定会有一个全局最优解。只要learning rate足够小，rmse肯定会下降。"]}]}