{"id": "1002038", "question": "非平衡分类任务中weighted log loss", "description": "<div class=\"col-md-11 col-xs-10\"><p>对于相对平衡的二元分类，我们一般用log loss</p><p>非平衡的二元分类有weighted log loss，但细节不大了解</p><p>weighted log loss具体是怎么weighted的，定义是怎么样的</p><p><br/></p></div>", "viewer": 5752, "tags": ["统计/机器学习", "监督式学习", "模型验证", "损失函数"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">正常的log loss</span></p><p><span style=\"font-size: 14px;\">$$\\text{logloss}=-\\frac{1}{n}\\sum_{i=1}^n\\left(y_i\\log(p_i)+(1-y_1)\\log(1-p_i)\\right)$$</span></p><p><span style=\"font-size: 14px;\">$y_i$是真实值，0或者1；$p_i$是预测出的为1的概率。</span></p><p><span style=\"font-size: 14px;\">加权重$r$，就是考虑到0和1的真实比例。weighted log loss可以写成</span></p><p><span style=\"font-size: 14px;\">$$\\text{logloss}_w=-\\frac{1}{n}\\sum_{i=1}^n\\left(ry_i\\log(p_i)+(1-r)(1-y_i)\\log(1-p_i)\\right)$$</span></p><p><span style=\"font-size: 14px;\">如果0标签样本较少，你想给它们加权重，那就可以让$r$取一个小于0.5的数值。</span></p><p><span style=\"font-size: 14px;\">还有一个比较直接的设置方法是让</span><span style=\"font-size: 14px;\">$r$是全部样本中是0的比例，比如100个样本，0有10个，那么$r=0.1$。</span></p><p><span style=\"font-size: 1rem;\"><br/></span></p></div>", "lvl2_answer": []}]}