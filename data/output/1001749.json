{"id": "1001749", "question": "k-medoids和k-means区别", "description": "<div class=\"col-md-11 col-xs-10\"><p>k-medoids和k-means的主要区别是什么？</p><p>我明白k-means，其实主要是不明白k-medoids。</p><p>最好是用浅显的语言描述下，鞠躬致谢！</p><p><br/></p></div>", "viewer": 8576, "tags": ["统计/机器学习", "无监督学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>看起来k-medoids和和K-means比较相似，但是K-medoids和K-means是有区别的，不一样的地方在于中心点的选取，在K-means中，我们将中心点取为当前cluster中所有数据点的平均值，在 K-medoids算法中，我们将从当前cluster 中选取这样一个点——它到其他所有（当前cluster中的）点的距离之和最小——作为中心点。</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>K means里每个cluster的中心点是平均值点</p><p>K medoids里每个cluster的中心点是离平均值点最近的样本点</p><p>也就是说K medoids的中心点一定是数据集中存在的点</p><p><br/></p></div>", "lvl2_answer": ["类似于mean和median的区别。", "不是吧，median对应的k-median吧，不是k-medoids"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>k-means,k-medians和k-medoids的 区别在于如何计算一个中心点代表整个cluster（让N对N的计算变为N对1）：</p><p>k-means： 算中心点时，每个属性（attribute）单独算，距离函数是L2norm。每个属性可能是数据中没出现过的值。</p><p>k-medians： 算中心点时，每个属性单独算，距离函数是L1norm。每个属性是数据中出现过的值，但可能来至于不动数据点，所以中心点可能在数据中没出现过。这是attribute意义上的median。</p><p>k-medoids： 算中心点时，所有属性一起算，距离函数是自定。中心点在数据中出现过。这是数据点意义上的median。</p><p>举个例子，2维binary的数据只有三种可能{（0,0），（0,1），（1,0）}。</p><p>k-means可能出现（0.6,0.6）的中心点，k-medians可能出现（1,1）的中心点，k-medoids不可能出现（1,1）的中心点。</p></div>", "lvl2_answer": ["不是非常理解。k-means的话，单独算和一起算，没有区别吧？k-medoids的话，既然距离是自定义的，为什么就一定是median呢？"]}]}