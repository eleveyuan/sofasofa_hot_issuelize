{"id": "1022161", "question": "不同mini-batch的LSTM_cell之间的隐藏状态(hidden state)和记忆单元(memory cell)的确定", "description": "<div class=\"col-md-11 col-xs-10\"><p>当我们在一个mini-batch上训练参数并转到另一个mini-batch时，如何得到新batch的c^&lt;0&gt;和a^&lt;0&gt; ?</p><p><br/></p><p>我的意思是，当处理第一个batch时，可以将c^&lt;0&gt;和a^&lt;0&gt;初始化为零，当完成该batch的训练时，将得到c^&lt;t&gt;和a^&lt;t&gt;。而在下一个batch中，是应该重新初始化c^&lt;0&gt;和a^&lt;0&gt;为0，还是将它们分配为上一批中的c^&lt;t&gt;和a^&lt;t&gt; ?</p></div>", "viewer": 2074, "tags": ["统计/机器学习", "深度学习", "自然语言处理"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>hidden state是要清零（初始化， 清零是一种简单的初始化）的，换了batch意味着新的数据。</p><p>你可以这么想，当你测试的时候，hidden state是不是要初始化？</p><p>真正在batch之间不断学习的是各个层的参数（模型）， hidden state是对数据的一种表示，数据不同hidden state肯定不同。</p></div>", "lvl2_answer": []}]}