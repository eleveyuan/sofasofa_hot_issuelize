{"id": "1000622", "question": "怎么理解库克距离(Cook's distance)?", "description": "<div class=\"col-md-11 col-xs-10\"><p>怎么理解回归中的库克距离(Cook's distance)?</p></div>", "viewer": 33968, "tags": ["统计/机器学习", "回归分析", "描述性统计"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>在线性回归中，库克距离(Cook's Distance)描述了<span style=\"font-weight: bold;\">单个样本对整个回归模型的影响程度</span>。库克距离越大，说明影响越大。库克距离也可以用来检测异常点。</p><p><br/></p><p>在最理想的情况下，每个样本对模型的影响是相等的。如某个样本的库克距离非常大，我们可以视为这个样本是异常点(outlier)。通常来说，若库克距离大于1，我们就认为这个点是异常点。也有人把这个阈值设置为$4/n$。</p><p><br/></p><p><br/></p><p><br/></p><p>----------如果想知道具体的计算公式，欢迎继续阅读----------</p><p>在线性回归中，</p><p>$$y = X\\beta + \\epsilon,$$</p><p>$y\\in\\mathbb{R}^n$, $X\\in\\mathbb{R}^{n\\times p}$, $\\beta\\in\\mathbb{R}^p$, $\\epsilon\\in \\mathbb{R}^{p}$。 这里考虑的是$n$个观测值的样本，自变量的数量为$p$，$\\epsilon$是误差向量。</p><p>我们知道这个线性回归的投影矩阵$H=X(X^TX)^{-1}X^T$，$h_i=x_i^T(X^TX)^{-1}x_i$是矩阵$H$对角线上的第$i$个元素。第$i$个样本的库克距离</p><p>$$D_i=\\frac{\\epsilon_i^2 h_i}{s^2 p (1-h_i)^2},$$</p><p>其中$s^2$是这个模型的均方误差MSE。</p></div>", "lvl2_answer": []}]}