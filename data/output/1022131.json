{"id": "1022131", "question": "随机森林回归输出的结果除了采用每棵决策树的平均值，还有别的方法吗？", "description": "<div class=\"col-md-11 col-xs-10\"><p>随机森林回归输出的结果除了采用每棵决策树的平均值，还有别的方法吗？只是好奇问问</p></div>", "viewer": 3653, "tags": ["统计/机器学习", "回归分析", "开放问题"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>随机森林属于Bagging集成学习中的一种，集成学习中的单模型结合策略 主要有三种方式，有平均法，投票法，学习法，具体为：\n</p><p><b>（1）\n平均法 </b></p><p>对于数值类的回归预测问题，通常使用的结合策略是平均法，也就是说，对于若干和弱学习器的输出进行平均得到最终的预测输出。  <br/></p><p><b>（2）\n投票法  </b></p><p>\n对于分类问题的预测，我们通常使用的是投票法。假设我们的预测类别是{c1,c2,...cK}对于任意一个预测样本x，我们的T个弱学习器的预测结果分别是(h1(x),h2(x)...hT(x))。最简单的投票法是相对多数投票法，也就是我们常说的少数服从多数，也就是T个弱学习器的对样本x的预测结果中，数量最多的类别ci为最终的分类类别。如果不止一个类别获得最高票，则随机选择一个做最终类别。稍微复杂的投票法是绝对多数投票法，也就是我们常说的要票过半数。在相对多数投票法的基础上，不光要求获得最高票，还要求票过半数。否则会拒绝预测。更加复杂的是加权投票法，和加权平均法一样，每个弱学习器的分类票数要乘以一个权重，最终将各个类别的加权票数求和，最大的值对应的类别为最终类别。  </p><p><b>\n（3）学习法  </b></p><p>\n上两种的方法都是对弱学习器的结果做平均或者投票，相对比较简单，但是可能学习误差较大，于是就有了学习法这种方法，对于学习法，代表方法是stacking，当使用stacking的结合策略时， 我们不是对弱学习器的结果做简单的逻辑处理，而是再加上一层学习器，也就是说，我们将训练集弱学习器的学习结果作为输入，将训练集的输出作为输出，重新训练一个学习器来得到最终结果。在这种情况下，我们将弱学习器称为初级学习器，将用于结合的学习器称为次级学习器。对于测试集，我们首先用初级学习器预测一次，得到次级学习器的输入样本，再用次级学习器预测一次，得到最终的预测结果。</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>对于随机森林回归，也可以用中位数或者分位数</p></div>", "lvl2_answer": []}]}