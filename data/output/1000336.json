{"id": "1000336", "question": "剪枝是什么意思", "description": "<div class=\"col-md-11 col-xs-10\"><p>经常在决策树或者类似的模型里看到“剪枝”这个词。这个词在机器学习里到底是什么意思？</p></div>", "viewer": 8822, "tags": ["统计/机器学习", "监督式学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-weight: bold;\">剪枝(prune)是一种防止决策树模型过拟合(over-fitting)的一种手段。</span>顾名思义，剪枝就是删去决策树中的一些树枝、树杈。</p><p><br/></p><p>\n</p><p>\n</p><p>剪枝又分为两类，一个是预剪枝(pre-pruning)另一个是后剪枝(post-pruning)。</p><p><br/></p><p>\n</p><p>\n</p><p><span style=\"font-weight: bold;\">预剪枝</span>就是在构建决策树的时候进行剪枝。通常决策树会不断生长，直到该树枝无法变得更纯（对于ID3决策树来说，就是无法使得熵更小）。我们可以通过设定一个阈值使得决策树提前终止生长。比如设定最小分叉样本数(sklearn RandomForest中的min_samples_split)，当该树杈上的样本小于所设定的min_sample_splt，树就不再继续生长。</p><p><br/></p><p>\n</p><p>\n</p><p><span style=\"font-weight: bold;\">后剪枝</span>就是在决策树在完全生长完之后，再剪去一些树枝、枝叶。方法也是类似的，我们先设定一个阈值。将某节点与其父节点合并，熵必然会增加，如果这个增加值小于这个阈值，我们最终就保留这个合并。这个过程由树叶逐渐向根部进行。</p><p><br/></p></div>", "lvl2_answer": []}]}