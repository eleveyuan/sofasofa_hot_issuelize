{"id": "1004187", "question": "特征相关性高的影响", "description": "<div class=\"col-md-11 col-xs-10\"><p>如果有十个特征，其中两个维度完全相同。那么这种情况有什么影响呢?</p><p>对LR、SVM、xgb、神经网络、FM等不同的模型都有什么影响呢？</p><p>谢谢</p></div>", "viewer": 6653, "tags": ["统计/机器学习", "特征选择"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">简单点说，</span><span style=\"font-size: 14px;\">对线性回归影响比较大，因为矩阵不可逆了；</span><span style=\"font-size: 14px;\">对线性模型，或者说广义线性模型、逻辑回归的影响不大，但是有可能会模型系数不收敛；对树类模型影响很小，可以参考</span><a href=\"http://sofasofa.io/forum_main_post.php?postid=1000876\" target=\"_blank\"><span style=\"font-size: 14px;\">决策树、随机森林中的多重共线性问题</span></a></p></div>", "lvl2_answer": ["谢谢您的回答，请问如果是FM模型会有什么影响呢？谢谢"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>特征相关性高往往影响的是模型的解释性和稳定性。</p><p>我觉得多重共线性对FM影响应该是不大，因为FM本质上和PCA是类似的，而PCA本身也是可以处理特征相关性的。</p></div>", "lvl2_answer": []}]}