{"id": "1002371", "question": "如果迫使一个线性回归模型的截距为0，会有什么坏处吗？", "description": "<div class=\"col-md-11 col-xs-10\"><p>由于特定问题的限制，这个线性回归模型的截距（常数项）必须为0，那么这么做会造成什么问题吗？</p><p>这个情况下，这个估计是有偏的还是无偏的呢？此外，还有什么顾忌呢？</p></div>", "viewer": 8605, "tags": ["统计/机器学习", "回归分析"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">参考</span><a href=\"https://en.wikipedia.org/wiki/Covariance_matrix#Block_matrices\" target=\"_blank\"><span style=\"font-size: 14px;\">Covariance_matrix</span></a><span style=\"font-size: 14px;\">，线性回归的假设是输入$X$和输出$Y$是联合正态分布。$X$是列向量，每一列为一个数据点。</span></p><p>$ \\mu_{X,Y} = \\begin{pmatrix} \\mu_{X} \\\\ \\mu_{Y} \\end{pmatrix} $</p><p><span style=\"font-size: 14px;\">$ \\Sigma_{X,Y} = \\begin{pmatrix} \\Sigma_{XX} &amp; \\Sigma_{XY} \\\\ \\Sigma_{YX} &amp; \\Sigma_{YY} \\end{pmatrix} $</span></p><p><span style=\"font-size: 14px;\">线性回归是求conditional mean </span></p><p><span style=\"font-size: 14px;\">$\\mu_{Y|X}=\\mu_Y+\\Sigma_{YX}\\Sigma_{XX}^{-1}(X-\\mu_X)$</span></p><p><span style=\"font-size: 14px;\">$=\\Sigma_{YX}\\Sigma_{XX}^{-1}X   + (\\mu_Y-\\Sigma_{YX}\\Sigma_{XX}^{-1}\\mu_X)$</span></p><p><span style=\"font-size: 14px;\">$=wX+b$</span></p><p><span style=\"font-size: 14px;\">其中$w=\\Sigma_{YX}\\Sigma_{XX}^{-1}$, </span></p><p><span style=\"font-size: 14px;\">$b=\\mu_Y-w\\mu_X$</span></p><p>如果要截距$b=0$，一个充分条件是$\\mu_Y=0$，$\\mu_X=0$。一般$X$要作normalization，可以保证$\\mu_X=0$，还需要让$\\mu_Y=0$。几何上意义是通过对原始数据$X,Y$的平移变换(Translation)，让拟合的直线过坐标的原点。</p><p>如果$X,Y$没有减去均值，而且强行令$b=0$ ，则偏差为$\\mu_Y-w\\mu_X$</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>我觉得你不应该人为的限制截距为0。</p><p>首先，如果常数项为0，那么它本质上已经不是一个正确的线性回归了。</p><p>其次，如果它本身的特征决定了常数项是0，应该不是由人为所决定，而是通过数据学习得到的。</p></div>", "lvl2_answer": []}]}