{"id": "1001161", "question": "对于xgboost，还有必要做很多特征工程吗？", "description": "<div class=\"col-md-11 col-xs-10\"><p>传统上来说，机器学习建模的第一步就是进行特征工程。但是似乎对于xgboost算法，特征工程显得没有那么举足轻重了（吗？）。</p><p><br/></p><p>就拿<a href=\"http://sofasofa.io/competition.php?id=1#c1\" target=\"_blank\">公共自行车使用量预测</a>这个题目来说，我做了特征工程和不做特征工程相比，结果并没有明显提高，很多时候甚至还是下降的。然而对于线性回归模型来说，是否做特征工程，效果则非常明显。</p><p><br/></p><p>不知针对这个例子，我想讨论的是，对于xgboost来说，特征工程是否还是那么必要吗？</p><p>谢谢！</p><p><br/></p></div>", "viewer": 24881, "tags": ["统计/机器学习", "监督式学习", "特征选择", "开放问题"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>特征工程是个很广的概念，包括特征筛选、特征变换、特征合成、特征提取等等。</p><p><br/></p><p>对于xgboost，它能够很好地做到特征选择，所以这一点不用我们去操心太多。</p><p><br/></p><p>至于特征变换（离散化、归一化、标准化、取log等等），我们也不需要做太多，因为xgboost是基于决策树，决策树自然能够解决这些。相比较来说，线性模型则需要做离散化或者取log处理。因为xgboost（树类模型）不依赖于线性假设。但是对于分类特征，xgboost需要对其进行独热编码，否则无法训练模型。</p><p><br/></p><p>xgboost也可以免于一部分特征合成的工作，比如线性回归中的交互项a:b，在树类模型中都可以自动完成。但是对于加法a+b，减法a-b，除法a-b这类合成的特征，则需要手动完成。</p><p><br/></p><p>绝大部分模型都无法自动完成的一步就是特征提取。很多nlp的问题或者图象的问题，没有现成的特征，你需要自己去提取这些特征，这些是我们需要人工完成的。</p><p><br/></p><p>综上来说，xgboost的确比线性模型要省去很多特征工程的步骤。但是特征工程依然是非常必要的。</p><p><br/></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>相对于线性模型来说，特征工程不是那么重要吧</p><p>线性模型有时候还需要做interaction term</p><p>决策树或者boosting都是模型自己在做interaction的。</p><p><br/></p></div>", "lvl2_answer": ["请问怎么理解决策树是模型自己在做interaction？", "同好奇", "这里很多人看不到，我单独发问题了", "看到了 希望有大神解答"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>从特征多重共线性的角度来说，xgboost可以省去很多特征工程的工程。</p><p>至于原因可以参考<a href=\"http://sofasofa.io/forum_main_post.php?postid=1000876\" target=\"_blank\">决策树、随机森林中的多重共线性问题</a></p><p><br/></p></div>", "lvl2_answer": []}]}