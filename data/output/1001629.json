{"id": "1001629", "question": "模型融合问题", "description": "<div class=\"col-md-11 col-xs-10\"><p>求问下模型融合，怎么知道两个单一模型融合后一定能够得到更优解呢</p><p>比如说SOFA 中自行车单一XGBOOST调参后能够达到15，而与逻辑斯特回归融合后却是下降，无论怎样分配权重都是，求大神指教<br/></p></div>", "viewer": 3899, "tags": ["统计/机器学习", "监督式学习", "开放问题", "数据竞赛"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>\"求问下模型融合，怎么知道两个单一模型融合后一定能够得到更优解呢\"</p><p><b>未必吧，没有科学道理啊</b></p><p><br/></p><p>“比如说SOFA 中自行车单一XGBOOST调参后能够达到15，而与逻辑斯特回归融合后却是下降”</p><p><b>为什么是逻辑回归呢？应该是线性回归吧</b></p><p><br/></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">模型融合能够提高精度的前提是你的base level模型是真的很base....不能上来就加boosting或者bagging啥的</span></p><p><span style=\"font-size: 14px;\"><br/></span></p></div>", "lvl2_answer": []}]}