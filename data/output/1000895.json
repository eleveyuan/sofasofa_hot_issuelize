{"id": "1000895", "question": "Gradient tree boosting和random forest (随机森林) 有什么区别和联系", "description": "<div class=\"col-md-11 col-xs-10\">这两个都属于集成学习(ensemble learning), 但是请问具体有何不同呢？</div>", "viewer": 7645, "tags": ["统计/机器学习", "监督式学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>随机森林属于平行集成(parallel ensemble), 也就是同时训练若干个决策树模型，希望它们尽量地相互独立，然后对所有的决策树的预测结果进行平均作为最终的预测结果。</p><p>Gradient Tree Boosting属于连续集成(consecutive ensemble)，也就是有顺序地训练若干的决策树模型。其大致过程如下。首先训练出一个决策树模型，接着再训练一个决策树，而这个新的决策树的目标变量（也就是想要预测的值）是前面所有决策树的预测结果和真实值之间的误差（residual）。也就是Gradient Tree Boosting是一个连续累加的过程。</p></div>", "lvl2_answer": []}]}