{"id": "1000966", "question": "牛顿法到底是一阶优化算法还是二阶优化算法？", "description": "<div class=\"col-md-11 col-xs-10\"><p>我知道牛顿法是利用一阶导数来求根的。<a href=\"http://sofasofa.io/forum_main_post.php?postid=1000182\">这个例子</a>也是用的一阶导数。</p><p>但是我最近又听很多人说牛顿法是二阶算法，所以我就混乱了。</p><p>请求指点！</p><p>谢谢！</p><p><br/></p></div>", "viewer": 10013, "tags": ["数学", "数值计算", "最优化"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>牛顿法是用来求根的。</p><p>比如说要求$f(x)=0$的解，先随机选个初始点$x_0$，然后开始迭代。迭代公式为</p><p>$$x_{n+1}=x_n-\\frac{f(x_n)}{f'(x_{n})}$$</p><p>当$|x_{n+1}-x_n|&lt;\\epsilon$时（$\\epsilon$为你设置的容忍误差），迭代结束，$x_{n+1}$就是$f(x)=0$的近似数值解。</p><p>可以清楚地看到，在迭代公式中我们使用了一阶导数$f'(x)$。所以此处牛顿法是一阶算法。</p><p><br/></p><p><span style=\"font-weight: bold;\">但是，当我们将牛顿法用作优化算法的时候，它就是二阶的。</span></p><p>假设我们有一个凸优化问题</p><p>$$\\min_{x} f(x)$$</p><p>也就是说我们要找一个$x$来最小化$f(x)$。对于凸优化问题，$f(x)$的最小值点就是$f(x)$的极值点，也就是导数为0的点。那么我们上面的<span style=\"font-weight: bold;\">优化问题就转换为了如下的求根问题</span>：</p><p>$$f'(x)=0.$$</p><p>利用牛顿法求解上面的式子，我们先选取初始点$x_0$，然后进行如下迭代</p><p>$$x_{n+1}=x_n-\\frac{f'(x_n)}{f''(x_n)}$$</p><p>直到$|x_{n+1}-x_n|&lt;\\epsilon$。</p><p>综上，牛顿法求根是一阶算法，我们将优化问题转为求根问题需要一阶导数，所以<span style=\"font-weight: bold;\">用牛顿法进行最优化是二阶算法。</span></p><p><span style=\"font-weight: bold;\"><br/></span></p></div>", "lvl2_answer": ["茅塞顿开！"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>当我们用牛顿法来求根，牛顿法是基于一阶导数的。</p><p>当我们用牛顿法来优化，牛顿法就是基于二阶导数的。</p></div>", "lvl2_answer": ["谢谢！"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>马什么梅，什么冬梅，马东什么？</p></div>", "lvl2_answer": []}]}