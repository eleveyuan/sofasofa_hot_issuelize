{"id": "1003214", "question": "adaboost做回归预测的时候，是怎么调整样本权重的？", "description": "<div class=\"col-md-11 col-xs-10\"><p>adaboost做分类的时候，分错的点会在下一轮获得更大的权重。那么用adaboost做回归的时候，这个权重是怎么来的？因为回归并不存在分对分错的情况。</p></div>", "viewer": 12390, "tags": ["统计/机器学习", "回归分析", "监督式学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">Adaboost做回归时误差率、权重系数如何选择：\n</span></p><p><span style=\"font-size: 14px;\">先看看回归问题的误差率的问题，对于第$m$个弱学习器，计算他在训练集上的最大误差:</span></p><p><span style=\"font-size: 14px;\">$$E_m=max\\left | y_i-G_m(x_i) \\right |\\quad i=1,2,...,N$$</span></p><p><span style=\"font-size: 14px;\">然后计算每个样本的相对误差:</span></p><p><span style=\"font-size: 14px;\">$$e_{mi}=\\frac{\\left | y_i-G_m(x_i) \\right |}{E_m}$$</span></p><p><span style=\"font-size: 14px;\">这里是误差损失为线性时的情况，如果我们用平方误差，则</span></p><p><span style=\"font-size: 14px;\">$$e_{mi}=\\frac{\\left ( y_i-G_m(x_i) \\right )^2}{E_m^2}$$</span></p><p><span style=\"font-size: 14px;\">最终得到第$m$个弱学习器的误差率:</span></p><p><span style=\"font-size: 14px;\">$$e_m=\\sum_{i=1}^Nw_{mi}e_{mi}$$</span></p><p><span style=\"font-size: 14px;\">我们再来看看如何得到弱学习器权重系数 \\alpha 。这里有：</span></p><p><span style=\"font-size: 14px;\">$$\\alpha_m=\\frac{e_m}{1-e_m}$$</span></p><p><span style=\"font-size: 14px;\">对于更新更新样本权重$D$，第$m+1$个弱学习器的样本集权重系数为:</span></p><p><span style=\"font-size: 14px;\">$$w_{m+1,i}=\\frac{w_{mi}}{Z_m}\\alpha_m^{1-e_{mi}}$$</span></p><p><span style=\"font-size: 14px;\">这里$Z_m$是规范化因子:</span></p><p><span style=\"font-size: 14px;\">$$Z_m=\\sum_{i=1}^{N}w_{mi}\\alpha_m^{1-e_{mi}}$$\n</span></p><p><span style=\"font-size: 14px;\">最后是结合策略，和分类问题稍有不同，采用的是对加权的弱学习器取中位数的方法，最终的强回归器为:\n</span></p><p><span style=\"font-size: 14px;\">$$f(x)=\\sum_{i=1}^{N}(ln\\frac{1}{\\alpha_m})g(x)$$</span></p><p><span style=\"font-size: 14px;\">其中，$g(x)$是所有$\\alpha_m G_m(x),m=1,2,....M$的中位数。</span></p><p><br/></p><p>-------------------------------------------------</p><p><span style=\"font-size: 14px;\"><b>AdaBoost回归算法总结起来就是：\n</b></span></p><p><span style=\"font-size: 14px;\"><b>输入：</b>训练数据集$T = \\left\\{ \\left( x_{1}, y_{1} \\right), \\left( x_{2}, y_{2} \\right), \\cdots, \\left( x_{N}, y_{N} \\right) \\right\\}$，其中$x_{i} \\in \\mathcal{X} \\subseteq R^{n}, y_{i} \\in \\mathcal{Y} = \\left\\{ +1, -1 \\right\\}, i = 1, 2, \\cdots, N$ \n</span></p><p><span style=\"font-size: 14px;\"><b>输出：</b>回归器$G\\left(x\\right)$</span></p><p><span style=\"font-size: 14px;\"><b>1. </b>初始化训练数据的权值分布\n</span></p><p><span style=\"font-size: 14px;\">$$D_{1}=\\left(w_{11},w_{12},\\cdots,w_{1N}\\right), \\quad w_{1i} = \\dfrac{1}{N}, \\quad i=1,2,\\cdots,N$$</span></p><p><span style=\"font-size: 14px;\"><b>2. </b>对$m=1,2,\\cdots,M$</span></p><p><span style=\"font-size: 14px;\"><b>    2.1 </b>使用具有权值分布$D_{m}$的训练数据集学习，得到基本分类器$G_{m}\\left(x\\right)$ \n</span></p><p><span style=\"font-size: 14px;\"><b>    2.2 </b>计算训练集上的最大误差\n</span></p><p><span style=\"font-size: 14px;\">$$E_m=max\\left | y_i-G_m(x_i) \\right |\\quad i=1,2,...,N$$</span></p><p><span style=\"font-size: 14px;\"><b>    2.3 </b>计算每个样本的相对误差（如果采用平方误差）:\n</span></p><p><span style=\"font-size: 14px;\">$$e_{mi}=\\frac{\\left ( y_i-G_m(x_i) \\right )^2}{E_m^2}$$</span></p><p><span style=\"font-size: 14px;\"><b>    2.4 </b>计算回归误差率:\n</span></p><p><span style=\"font-size: 14px;\">$$e_m=\\sum_{i=1}^Nw_{mi}e_{mi}$$</span></p><p><span style=\"font-size: 14px;\"><b>    2.5 </b>计算弱学习器的系数\n</span></p><p><span style=\"font-size: 14px;\">$$\\alpha_m=\\frac{e_m}{1-e_m}$$</span></p><p><span style=\"font-size: 14px;\"><b>    2.6 </b>更新样本集的权重分布为\n</span></p><p><span style=\"font-size: 14px;\">$$w_{m+1,i}=\\frac{w_{mi}}{Z_m}\\alpha_m^{1-e_{mi}}$$</span></p><p><span style=\"font-size: 14px;\">    其中， $Z_{m}$是规范化因子\n</span></p><p><span style=\"font-size: 14px;\">$$Z_k=\\sum_{i=1}^{N}w_{ki}\\alpha_k^{1-e_{ki}}$$</span></p><p><span style=\"font-size: 14px;\"><b>3. </b>构建基本分类器的线性组合\n</span></p><p><span style=\"font-size: 14px;\">$$f(x)=\\sum_{m=1}^{M}(ln\\frac{1}{\\alpha_m})g(x)$$</span></p><p><span style=\"font-size: 14px;\">其中，$g(x)$是所有$\\alpha_mG_m(x),m=1,2,....M$的中位数。</span></p><p><span style=\"font-size: 14px;\"><br/></span></p><p><span style=\"font-size: 14px;\">参考来源：</span><a href=\"http://www.cnblogs.com/pinard/p/6133937.html\" target=\"_blank\">http://www.cnblogs.com/pinard/p/6133937.html</a></p></div>", "lvl2_answer": []}]}