{"id": "1000518", "question": "sklearn模块里的DecisionTreeClassifier为什么每次结果不同（数据相同的情况下）", "description": "<div class=\"col-md-11 col-xs-10\"><p>我用sklearn里的DecisionTreeClassifier，发现每次结果（预测结果和score）都有稍微不同，模型参数和数据每次都是一样的。这是bug么？源代码不稳定？</p></div>", "viewer": 12309, "tags": ["统计/机器学习", "监督式学习", "Python"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>sklearn.tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, <span style=\"font-weight: bold; color: rgb(206, 0, 0);\">random_state=None</span>, max_leaf_nodes=None, min_impurity_split=1e-07, class_weight=None, presort=False)</p><p>这个是sklearn.tree.DecisionTreeClassifier的全部参数，其中有一项是random_state，如果你没有特地设定这个数值的话，决策树是有随机性的。</p><p><br/></p><p>-------------------------来个分界线--------------------------</p><p><br/></p><p>在sklearn的记录文档里是这么写的，考虑到数值特征的存在，训练一个最优的决策树是NP-complete。因此比较实际的做法是努力去找一个比较优的，而不是最优的。比如用贪婪算法，随机地从一些特征开始建立次优化的决策树，再从这些树中选择最好的，这样的树能达到较优。</p><p><br/></p></div>", "lvl2_answer": []}]}