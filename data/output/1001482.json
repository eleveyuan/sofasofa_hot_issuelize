{"id": "1001482", "question": "可以对线性回归进行boosting吗？", "description": "<div class=\"col-md-11 col-xs-10\"><p>例如将GBDT中的弱分类器换成LR？</p></div>", "viewer": 4826, "tags": ["统计/机器学习", "回归分析", "监督式学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>对线性回归boost并没有意义，因为叠加多个线性回归最后还是线性回归</p><p>比如第一个线性回归$a_1x+b_1$</p><p>第二个线性回归$a_2x+b_2$</p><p>将这两个相加，得到的是</p><p>$(a_1+a_2)x+(b_1+b_2)$，依然是个线性回归</p><p><br/></p><p>线性回归是有解析解的，一旦求出一个线性回归，那一定是最优的，叠加也没有意义</p><p><br/></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>这个和xgb中的弱分类器LR是一个意思，其实本质上没有被boost，只是被迭代求解而已。</p><p>可以参考我之前问过的问题：<a href=\"http://sofasofa.io/forum_main_post.php?postid=1001016\" target=\"_blank\">xgboost的gblinear是什么意思？</a></p><p><br/><br/></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>可以，但是没有意义，也没有必要，boost完之后也没有区别。</p><p><br/></p></div>", "lvl2_answer": []}]}