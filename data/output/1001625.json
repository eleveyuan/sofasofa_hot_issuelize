{"id": "1001625", "question": "RMSProp的直白解释", "description": "<div class=\"col-md-11 col-xs-10\"><p>本人比较笨，不大能够理解RMSProp算法。</p><p>我基本明白sgd。</p><p>求大神用直白语言解释一下RMSProp。谢谢！</p><p><br/></p></div>", "viewer": 3990, "tags": ["数学", "数值计算", "最优化"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>1.RMSProp是AdaGrad算法的改进。鉴于神经网络都是非凸条件下的，RMSProp在非凸条件下结果更好，改变梯度累积为指数衰减的移动平均以丢弃遥远的过去历史。\r\n</p><p>\n</p><p>2.经验上，RMSProp被证明有效且实用的深度学习网络优化算法。</p><p>与AdaGrad相比，RMSProp增加了一个衰减系数来控制历史信息的获取多少。</p><p>所以我建议题主先看一下adagrad的算法实现</p></div>", "lvl2_answer": []}]}