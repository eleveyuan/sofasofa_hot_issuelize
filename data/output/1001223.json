{"id": "1001223", "question": "训练误差、测试误差、泛化误差的区别", "description": "<div class=\"col-md-11 col-xs-10\"><p>训练误差、测试误差、泛化误差这三者都是误差</p><p>我大概能明白训练误差是什么</p><p>那么测试误差、泛化误差又有什么区别</p><p>这三者又有什么联系呢</p><p><br/></p></div>", "viewer": 8524, "tags": ["统计/机器学习", "监督式学习", "模型验证", "开放问题"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>我还想补充个<b>验证误差</b>。</p><p>训练过程中的误差，就是<b>训练误差</b>。</p><p>在验证集上进行交叉验证选择参数（调参），最终模型在验证集上的误差就是<b>验证误差</b>。</p><p>训练完毕、调参完毕的模型，在新的测试集上的误差，就是<b>测试误差</b>。</p><p>假如所有的数据来自一个整体，模型在这个整体上的误差，就是<b>泛化误差</b>。通常说来，测试误差的平均值或者说期望就是泛化误差。</p><p><br/></p><p>综合来说，它们的大小关系为</p><p>训练误差 &lt; 验证误差 &lt; 测试误差 ～= 泛化误差</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>训练误差是模型在训练集上的误差</p><p>测试误差是模型在测试集上的误差</p><p>泛化误差是用来衡量模型的泛化性  </p></div>", "lvl2_answer": []}]}