{"id": "1000505", "question": "Stratified k-fold cross validation(分层交叉验证)", "description": "<div class=\"col-md-11 col-xs-10\"><p>Stratified cross validation和一般cross validation有什么区别？</p></div>", "viewer": 11505, "tags": ["统计/机器学习", "模型验证"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>对于常规的k-fold CV，每个fold都是从训练集随机抽出来。</p><p>对于stratified k-fold CV，每个fold都是按照类别的比例抽出来的。</p><p><br/></p><p>比如这个分类任务一共有三个类别A、B、C，它们的比例是1:2:10。那么每个fold中的A、B、C的比例也必须是1:2:10。</p><p>stratified k-fold CV实现起来也很容易。先把A类别的数据随机分成k组，再把B类数据分成k组，然后C类分成k组，最后再把它们合并起来，就得到了k组满足1:2:10的数据了。</p><p>stratified cross validation是优于一般的cross validation的。因为test set能充分代表整体数据，此外CV出来的k个预测结果的方差也会变小，使得cv error更可靠。</p><p>对于非平衡分类，stratified CV的优点就更加明显了。如果二元分类中分类A只占有0.01%，分类B占有99.99%，当你使用常规的CV的时候，可能你的训练集里甚至都没有足够的A来训练，或者测试集里A的数量极少，严重影响了验证结果的可靠性。</p><p><br/></p></div>", "lvl2_answer": ["学习了！还从没有用过stratified cv"]}]}