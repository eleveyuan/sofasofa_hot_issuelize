{"id": "1002266", "question": "PCA会降低分类器的精度吗？", "description": "<div class=\"col-md-11 col-xs-10\"><p>我要建立一个二元分类器，因为数据维数比较大，我考虑了先做PCA来降维，然后再做一个分类器。</p><p>我试了好几个算法，比如决策树，随机森林，gbm，发现总是直接原始数据训练出来的模型精度很高，用PCA降维后的数据训练的模型精度较低。</p><p>请问理论上讲PCA会降低分类器的精度吗？</p><p><br/></p></div>", "viewer": 9021, "tags": ["统计/机器学习", "监督式学习", "数据预处理", "数据降维"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>pca后testing精度变好和变坏都见过。和很多因素有关，比如pca前要normalization，能量阈值（99%）的选择，数据本身的复杂度（是否能用线性模型表示），模型的拟合复杂函数的能力（线性或深度神经网络），还有模型的训练程度（overfitting或者underfitting）。pca原本是针对简单数据和线性模型，如果数据和模型都很复杂，pca效果很难保证。</p><p>我理解是两种情况下pca有好处：1.损失的信息里噪音占多数，有人说相当于加了正则项；2.模型太弱（比如线性），本来就提取不出被扔掉的信息，反而会学到一部分噪音。</p><p>非线性降维可以了解下kernel pca，t-SNE，autoencoder。</p><p>------------------------------------------------</p><p>举例说明下PCA在线性回归里的作用。</p><p>$y=Xw$里$w=X^{-1}y=(X^TX)^{-1}Xy$。 当$X$的condition number很大时（ill-conditioned），$(X)^{-1}$会有很大误差，比如放大$X$里的round-off error。而condition number是$X$的最大singular value/最小singular value。</p><p>PCA的作用是：</p><p>$PCA(X)=SVD(X)=USV^T$,而X的singular value$S$等于$X^TX$的eigen value的平方根。</p><p>$X^{-1}=VS^{-1}U^T$。$s_i$指第i个singular value。假如$s_i=10^{-30}$ 则 $1/s_i=10^{30}$ 。也就说$s_i$很小的维度，误差会放大很多。</p><p>PCA降维就是扔掉$S$中很小的一些维度，变向减小了剩余的$X_1$的condition number, 让$X_1^{-1}$ 的误差更小。</p><p>正则项作用：</p><p>如果不用PCA扔掉这些$s_i$小的维度，还可以用正则项（比如 Tikhonov regularization），相当于在$s_i=s_i+c$, $c$是一常数，这样也能降低$X$的condition number。比如加正则项前condition number=100/0.001=100000，加正则项后condition number=(100+1)/(0.001+1)=100.899，变小了1000倍。</p><p><br/></p><p><br/></p></div>", "lvl2_answer": ["讲得很好！"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">很多时候，我们在分类或者回归任务前先PCA降维，不一定是为了精度。可能是为了</span></p><ol><li><span style=\"font-size: 14px;\">为了可视化（降到2或者3维）</span></li><li><span style=\"font-size: 14px;\">为了减小数据量、增加训练速度</span></li><li><span style=\"font-size: 14px;\">为了去掉冗余的特征</span></li></ol><p><span style=\"font-size: 14px;\">在PCA之后，数据的维度降低，必然会造成信息丢失，减少的维度越多，丢失信息越多；同时，数据中的噪声也可能被降低。所以精度可能提高、也可能降低。</span></p><p><span style=\"font-size: 14px;\">最直接的方法是做cross validation，选出最佳的PCA后数据的维度。</span></p><p><br/></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>我理解的PCA就是在总体上降低数据的信息量，在删减数据的时候难免会同时删减有效信息和噪音信息。</p><p>当删减噪音信息比较多的时候，PCA就是对精度有帮助的。</p><p>当删减有效信息比较多的时候，PCA就是对精度有反作用的。</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>我觉得会的，因为降维毕竟会损失很多信息。</p><p><br/></p></div>", "lvl2_answer": []}]}