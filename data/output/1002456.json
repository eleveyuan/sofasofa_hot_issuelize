{"id": "1002456", "question": "如何理解神经网络的Universal approximation theorem？", "description": "<div class=\"col-md-11 col-xs-10\"><p>如何理解神经网络的Universal approximation theorem？有什么实际指导意义吗？</p></div>", "viewer": 8984, "tags": ["统计/机器学习", "开放问题", "人工神经网络"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>Universal approximation theorem的意思说，<b>对于一个前馈神经网络，哪怕只有一个隐藏层，它也能无限逼近任何有界连续函数</b>。</p><p>换句话说，理论上说，用前馈网络做回归任务，一个隐藏层足够了。</p><p>类似的还有另外一个结论，<b>对于一个前馈神经网络，哪怕只有一个隐藏层，它也能完全拟合任何0-1函数</b>。</p><p>换句话说，理论上说，用前馈网络做二元分类任务，一个隐藏层足够了。</p><p><br/></p><p>其实定理还包含了一个隐藏信息：如果是做多元分类任务，一个隐藏层是远远不够的。</p></div>", "lvl2_answer": ["是不是也侧面反映了特征工程的重要性。。。", "我觉得是的"]}]}