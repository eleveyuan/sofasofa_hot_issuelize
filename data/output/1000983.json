{"id": "1000983", "question": "stack多个xgboost效果并不理想", "description": "<div class=\"col-md-11 col-xs-10\"><p>我在尝试那个汽车保险的练习赛，我train了五个不同的xgboost的模型（模型参量不同）。然后我把这几个模型stack在一起之后的预测roc auc反而不如单个最好的那个xgboost。是我哪里做错了吗？还是有什么隐藏的技巧？</p><p><br/></p><p>补充：我说的stack就是把五个xgboost的预测结果取均值。</p></div>", "viewer": 6741, "tags": ["统计/机器学习", "监督式学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>如果每个xgboost都是用一样的数据、一样的特征训练出来的，那么它们会具有更高的相关性。用多个相关性高的模型进行组装，通常效果不会很好，一般来说是不会超过这几个模型最好的那个的。</p><p><br/></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>stack的时候一定要让各个模型多样化，百家争鸣那种，而不是千篇一律。你都是用xgb的话，模型应该很相似。</p><p>此外，stack本身也并不能确保总是有效的，有兴趣的话可以看看这篇论文<a href=\"https://link.springer.com/content/pdf/10.1023/B:MACH.0000015881.36452.6e.pdf\" target=\"_blank\">Is Combining Classifiers with Stacking Better than Selecting the Best One?</a></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>stack多个模型就好比街头采访，采访的人越多越好，但同时被采访对象越多样性，越容易得到接近真实的反馈信息。</p><p>1、相关性高的模型stack在一起通常效果不好的。因为它们没有足够的多样性，彼此之间并不能提供很多不同的信息。</p><p>2、你也可以试试加权取平均，而不是等权重的平均。</p><p><br/></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>我感觉这个也是要看运气的（我算是新鲜人，不太懂）。</p><p>有时候stack一样效果就很好，有时候stack一下效果反而很烂，感觉和数据本身关系挺大的。效果可能也挺随机的，cross validation的效果好就用，不好就不用。</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>楼主可以尝试在每组xgb的特征上引入差异性</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>题主的方法准确地说应该是bagging，而不是stack吧</p></div>", "lvl2_answer": ["stacking和bagging的区别：http://sofasofa.io/forum_main_post.php?postid=1001591", "想说averaging的，打错了，不好意思。看了你给的链接，averaging应该还是属于stacking的 谢谢", "所以也并不是真正意义的stacking，也不是bagging"]}]}