{"id": "1004509", "question": "线性回归的目标函数是凸函数吗？", "description": "<div class=\"col-md-11 col-xs-10\"><p>线性回归的目标函数是凸函数吗？怎么推导呢？</p></div>", "viewer": 7797, "tags": ["统计/机器学习", "数值计算", "最优化", "回归分析", "损失函数"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>很显然是凸函数。@cabbage 推导了如何得到目标函数。</p><p>对于线性回归，目标函数很简单，就是平方损失</p><p>假设是单变量的线性回归$y=ax+b+\\epsilon$，那么损失函数</p><p>$$L=\\frac{1}{n}\\sum_{i=1}^n(ax_i+b-y_i)^2$$</p><p>要证明这个损失函数是关于$a,b$的凸函数，我们就只需要求二阶偏导</p><p>$$\\frac{\\partial L}{\\partial a}=\\frac{1}{n}\\sum_{i=1}^n2x_i(ax_i+b-y_i)$$</p><p>$$\\frac{\\partial^2 L}{\\partial a^2}=\\frac{1}{n}\\sum_{i=1}^n 2x_i^2\\geq 0$$</p><p>所以$L$关于$a$的二阶导是非负的</p><p>$$\\frac{\\partial L}{\\partial b}=\\frac{1}{n}\\sum_{i=1}^n2(ax_i+b-y_i)$$\n</p><p>$$\\frac{\\partial^2 L}{\\partial b^2}=\\frac{1}{n}\\sum_{i=1}^n 2 \\gt 0$$</p><p>所以$L$关于$b$的二阶导也是非负的</p><p>所以损失函数$L$是关于$a$和$b$的凸函数。</p><p><br/></p><p>对于多变量线性回归也是一样的推导方法，可以证明是凸函数。</p></div>", "lvl2_answer": ["厉害厉害"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>我们用$\\epsilon^{(i)}$代表误差，则预测函数可以写为</p><p>$$y^{(i)} = \\theta^Tx^{(i)}+\\epsilon^{(i)}$$</p><p>$$\\epsilon^{(i)} = y^{(i)} -\\theta^Tx^{(i)}$$\n</p><p>\n</p><p>其中，我们假设误差是随机分布的，均值为0，服从高斯分布$N(0,\\sigma)$，因为根据中心极限定理，服从高斯分布也是对误差项分布的合理猜想。\n</p><p>\n</p><p>所以\n</p><p>\n</p><p>$$P(y^{(i)}|x^{(i)}; θ) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\text{exp}(- \\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})$$\n</p><p>\n</p><p>$P(y^{(i)}|x^{(i)}; θ)$表示：在$\\theta$为给定的参数的情况下，概率$y^{(i)} $以$x^{(i)} $为随机变量的概率分布，注意$\\theta$不是随机变量。\n</p><p>\n</p><p>由于$\\epsilon^{(i)}$是独立的同分布`IID：independentlyidentically distribution`，所以以$\\theta$为变量的似然函数为：\n</p><p>\n</p><p>$$L(θ)=L(θ;X,Y)=p(Y|X;θ) = \\prod_{i=1}^{m}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\text{exp}(- \\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})$$\n</p><p>\n</p><p>对 $L(θ) $取对数有：\n</p><p>\n</p><p>$$l(\\theta)=\\log L(\\theta) = \\log\\prod_{i=1}^{m}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\text{exp}(- \\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})$$\n</p><p>\n</p><p>$$= m\\log\\frac{1}{\\sqrt{2\\pi}\\sigma} - \\frac1{2\\sigma^2}\\sum_{i=1}^{m}(y^{(i)}-\\theta^Tx^{(i)})^2$$\n</p><p>\n</p><p>最大化$l(\\theta)$即是最小化$\\frac1{2\\sigma^2}\\sum_{i=1}^{m}(y^{(i)}-\\theta^Tx^{(i)})^2$，这样就是`loss function`</p></div>", "lvl2_answer": []}]}