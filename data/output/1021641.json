{"id": "1021641", "question": "为什么对线性回归应用boosting没用？", "description": "<div class=\"col-md-11 col-xs-10\"><p>线性回归的偏差较大，boosting可以降低偏差。<span style=\"font-size: 1rem;\">没用是因为boosting降低偏差的方法对线性回归不适用吗？</span></p><p><br/></p><p>希望可以尽量详细回答，本人机器学习小白</p><p><br/></p></div>", "viewer": 1682, "tags": ["数学", "回归分析", "监督式学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>比如训练集是$\\{(X_1,y_1),(X_2,y_2),(X_3,y_3),\\ldots,(X_n,y_n)\\}$</p><p>训练得到一个线性回归模型$\\hat y = X\\beta_1$。按照boosting的思想，我们要用真实值减去模型的预测值，得到第二轮训练的真实标签，所以第二轮的训练集是$\\{(X_1,\\epsilon_1),(X_2,\\epsilon_2),(X_3,\\epsilon_3),\\ldots,(X_n,\\epsilon_n)\\}$。这时你可以再训练一个线性回归得到$\\hat \\epsilon = X\\beta_2 $。</p><p>如果此时停止迭代，那么你得到的最终模型就是应该是$X(\\beta_1+\\beta_2)$，本质上还是线性回归模型。这个新模型是可以最小化平方误差的。而$X\\beta_1 $也是最小化平方误差的，所以两者是等价的。所以boosting没有意义。实际上$\\beta_2=0$。</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>boosting是bagging的进阶版，实际上连bagging对线性回归都没有效果，何况是boosting呢？</p><p>线性回归和bagging的讨论可以看这个<a href=\"http://sofasofa.io/forum_main_post.php?postid=1000740\" target=\"_blank\">线性回归的bagging</a></p></div>", "lvl2_answer": []}]}