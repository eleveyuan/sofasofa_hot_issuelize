{"id": "1001978", "question": "L1正则化和L2正则化的区别?L1为啥具有稀疏性？", "description": "<div class=\"col-md-11 col-xs-10\"><p>机器学习萌新一枚。</p><p>只知道正则化可以用来调节系数权重，处理过拟合</p><p>求大佬告知其中的区别,以及L1为啥具有稀疏性？</p></div>", "viewer": 6302, "tags": ["统计/机器学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>在线性模型里</p><p><b>L1对应的是LASSO</b></p><p><b>L2对应的是Ridge</b></p><p>我来做个搬运工吧</p><p><a href=\"http://sofasofa.io/forum_main_post.php?postid=1001156\" target=\"_blank\">为什么L1能够用来选择特征，L2却不能</a><br/></p><p><a href=\"http://sofasofa.io/forum_main_post.php?postid=1001177\" target=\"_blank\">L1和L2分别是什么意思</a></p><p><br/><br/></p></div>", "lvl2_answer": ["L1为啥具有稀疏性？", "请参考我上面回答中的第一个链接。"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>L2正则相当于是高斯先验</p><p>L1正则相当于是拉普拉斯先验</p><p><br/></p></div>", "lvl2_answer": ["正则项是L1norm（x）时，x满足拉普拉斯分布，比较稀疏\n正则项是L2norm（x）时，x满足高斯分布，不是太稀疏", "L1为啥具有稀疏性？"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">L1正则化是一范式，而</span><span style=\"font-size: 14px;\">L2正则化是二范式。简单来说在线性模型中，L1的惩罚系数是关于w的一次方，L2的惩罚系数是关于w的平方，类似于$|w|$和$\\frac{1}{2}|w|^{2}$</span></p></div>", "lvl2_answer": ["L1为啥具有稀疏性？"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>直观上来理解一下, 对损失函数施加 L0/L1/L2 范式约束都会使很多参数接近于0. 但是在接近于0的时候约束力度会有差别. 从导数的角度看, L1正则项 在0附近的导数始终为正负1, 参数更新速度不变. L2 在0附近导数接近于0, 参数更新缓慢. 所以 L1 相比 L2 更容易使参数变成0, 也就更稀疏, </p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">还有就是同样的数，值小的时候，L1范式与l2范式差异不大，值大的时候，L2范式与L1差异大，也就是L2对大数的惩罚力度更大</span></p><p><span style=\"font-size: 14px;\"><br/></span></p></div>", "lvl2_answer": ["L1为啥具有稀疏性？"]}]}