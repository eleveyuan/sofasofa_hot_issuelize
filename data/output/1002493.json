{"id": "1002493", "question": "用SGD时陷入局部最优解的解决方法", "description": "<div class=\"col-md-11 col-xs-10\"><p>我自己用SGD实现了一个算法，但是似乎陷入了局部最优。这种情况一般如何解决？</p></div>", "viewer": 6827, "tags": ["数学", "数值计算", "最优化"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>可尝试随机地增大学习速率/学习步长。其想法是像模拟退火算法样，在优化时有一定概率接受非最优解，从而增大跳出局部最优的概率。</p><p>在每个epoch/iteration后需要把数据洗牌一遍，让每个batch的数据都不一样。我的理解是每个data point的loss funtion曲面不一样，一个batch的曲面是相关曲面的平均。如果每次batch中data不一样，也就是曲面都不一样，那就减小了停在局部最优的可能性。</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>可以尝试更多的初始值</p><p>也可以使用更好的优化算法，如动量、Adam</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>有可能是初始点不好，也可能是学习率太小。</p><p><br/></p></div>", "lvl2_answer": []}]}