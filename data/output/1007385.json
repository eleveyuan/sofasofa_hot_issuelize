{"id": "1007385", "question": "为什么很少用L0范数惩罚正则项？", "description": "<div class=\"col-md-11 col-xs-10\"><p>通常用到得都是L1和L2，为什么很少用L0范数惩罚正则项？</p></div>", "viewer": 2319, "tags": ["统计/机器学习", "监督式学习", "特征选择"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>L0范数加入进去就是 NP hard问题了。L1范数和L2范数作为惩罚项，可以进行起码的求导操作。只有在面对特定的问题下，比如压缩感知获取稀疏解，也是将L0转换为L1范数的等价形式来进行求解最优值的。</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>L0性质不好，L0范数不具有范数的性质，范数具有距离，三角不等式，齐次性。可以看林青老师的凸优化课程，也可以去看泛函分析的相关内容。</p></div>", "lvl2_answer": []}]}