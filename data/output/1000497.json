{"id": "1000497", "question": "回归中自变量和因变量的相关系数和回归系数（斜率）有什么关系？", "description": "<div class=\"col-md-11 col-xs-10\"><p>我自己观察到的现象是，自变量和因变量的相关系数越大，在线性回归中这个自变量的系数就越大。它们是正相关的关系吗？</p></div>", "viewer": 17868, "tags": ["统计/机器学习", "回归分析", "描述性统计"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>对于一元简单线性回归</p><p>$$Y=\\beta X + \\beta_0 + \\epsilon$$</p><p>我们知道</p><p>$$\\beta = \\frac{\\text{Cov}(X,Y)}{\\text{Var}(X)}=\\text{Cor}(X,Y)\\frac{\\sigma_Y}{\\sigma_X}$$</p><p>可以看出$\\beta$的确是和$\\text{Cor}(X,Y)$正相关的（标准差$\\sigma_X$和$\\sigma_Y$都是正数）。</p><p>如果我们把自变量$X$和因变量$Y$都先进行标准化处理，使得$\\sigma_X=\\sigma_Y=1$，那么回归系数$\\beta$就等于$X$和$Y$的皮尔逊相关系数了。</p><p><br/></p><p><br/></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">确实学习的参数正比于输入和输出皮尔逊相关系数。</span></p><p><span style=\"font-size: 14px;\">用列向量矩阵表示的最小二乘公式   </span></p><p><span style=\"font-size: 14px;\">$$\\hat{y}^T=X_{new}^T(XX^T)^{-1}Xy^T$$</span></p><p><span style=\"font-size: 14px;\">$\\Sigma_{XX}=XX^T$是covariance matrix,是半正定的实对称方阵，可做</span><a href=\"https://en.wikipedia.org/wiki/Matrix_decomposition#Eigendecomposition\" target=\"_blank\"><span style=\"font-size: 14px;\">eigendecomposition</span></a><span style=\"font-size: 14px;\">， </span><span style=\"font-size: 14px;\">$XX^T=Q\\Lambda Q^T$。其中$Q$是$\\Sigma_{XX}$的eigen vector，把输入$X$投影到相互独立的eigen space，对角线矩阵$\\Lambda$表示每个eigen vector轴上的variance，</span></p><p><span style=\"font-size: 14px;\"> covariance matrix逆是partial covariance matrix,  $(XX^T)^{-1}=Q\\Lambda^{-1} Q^T=QD(QD)^T$，其中对角线矩阵$D=D^T, DD^T=\\Lambda^{-1}$</span></p><p><span style=\"font-size: 14px;\">$$\\hat{y}^T=(X_{new}^TQD)(X^TQD)^Ty^T$$</span></p><p><span style=\"font-size: 14px;\">令 $Z^T=X^TQD$</span></p><p><span style=\"font-size: 14px;\">$$\\hat{y}^T=Z_{new}^T Zy^T$$</span></p><p><span style=\"font-size: 14px;\">$$\\hat{y}^T=Z_{new}^T\\Sigma_{Zy}$$</span></p><p><span style=\"font-size: 14px;\">数据流程是：$X$经过独立化算子$Q$和标准化算子$D$得到新特征$Z$,最小二乘模型学习的是$\\Sigma_{Zy}$。如果$y$经过标准化（$\\sigma_y=1$），则学习的系数就是$Corr(Z,y)$。</span></p><p><span style=\"font-size: 14px;\">一个理想情况是$X$本身个特征独立并输入输出都经过标准化，$X=Z$，则$w=corr(X,y)$。</span></p><p><span style=\"font-size: 14px;\">----------------------------</span></p><p><span style=\"font-size: 14px;\">这满足以最小二乘为代表的基于随机变量相关性的机器学习方法的流程：先把数据压缩成互不相关的信号（要求编码向量$Z$正交），再学习编码和输出的相关性（$\\Sigma_Zy$），最后把新编码$Z_{new}$解码到输出空间。autuencode也符合这个流程。</span></p><p><br/></p><p><br/></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>自变量和因变量的相关系数和正规化后的回归系数是相等，它们的平方就等于$R^2$</p></div>", "lvl2_answer": []}]}