{"id": "1004125", "question": "为什么小数据不适合神经网络模型？", "description": "<div class=\"col-md-11 col-xs-10\"><p>很多文章上都说数据量小的时候，不能用神经网络和深度学习，这是为什么？有什么理论吗？</p></div>", "viewer": 4689, "tags": ["统计/机器学习", "深度学习", "人工神经网络"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">神经网络是图结构，因为有非线性层比如relu，有的从输入到输出的路径只有一部分数据能流过。大部分数据会被relu挡住，选择走别的路<span style=\"font-size: 14px;\">径。如果有条路径只有一个数据流过，那么这条路径上学习到的参数就会逼近这个数据的噪音，变成过拟合。流过数据点越多，噪音相互抵消，通用性（generalization）越好。</span></span><span style=\"font-size: 14px; -webkit-tap-highlight-color: transparent; text-size-adjust: 100%;\">如果训练数据点太少，神经网络很多路径只有较少数据流过，会过拟合。</span></p><p><span style=\"font-size: 14px;\">这也是在loss中加L1/L2 norm的正则项，添加dropout，让网络有效路径更稀疏，强迫更多数据去共享路径，让数据更集中。</span></p><p><span style=\"font-size: 14px;\">有个<a href=\"https://en.wikipedia.org/wiki/One_in_ten_rule\" target=\"_blank\">经验公式</a>，每个参数（事件）需要10（或更多）数据点去支持。可理解为<b>一个参数要吃到10个数据才能喂饱</b>，越多越好。</span></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>神经网络和深度学习过于复杂，容易出现过拟合。</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>神经网络容易在小数据上过拟合。</p><p>为什么呢？对于一个三四层的全连接网络，其中的参数可能会多达上几百个。这样就会造成需要被学习的参数多于或者接近训练样本的个数的情况，于是相当于数据量本身，模型过于复杂，就发生了过拟合。</p></div>", "lvl2_answer": []}]}