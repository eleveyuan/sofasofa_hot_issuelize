{"id": "1000323", "question": "关于随机梯度下降法(SGD)的问题", "description": "<div class=\"col-md-11 col-xs-10\"><p>如果训练集中有500的样本，随机梯度下降法的步长是固定的，我每次选一个样本，那么每次迭代时另外499个就没用了？</p><p><br/></p></div>", "viewer": 4787, "tags": ["数学", "数值计算"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>是的。对于每一次更新，我们只是随机地挑选一个样本，然后根据这个样本来确定下降方向。但是这并不代表剩下的没有用呀，在下一次更新的时候，我们还会从这500个里随机挑一个。因为一般来说步长比较小，达到最终收敛，我们会迭代很多次，每次随机挑一个，这样很多样本都会被用到。</p><p>如果你是想每次迭代的时候多用几个样本点的话，可以考虑使用小批量梯度下降法(Mini-Batch Gradient Descent)。MBGD是每次随机选出m个样本点，然后对这m个点的梯度求平均值，这个平均值就是下降的反方向。</p></div>", "lvl2_answer": []}]}