{"id": "1000545", "question": "如果我用交叉验证，还是否需要单独分出测试集？", "description": "<div class=\"col-md-11 col-xs-10\"><p>比方说我用100k条数据，我有两个思路</p><p>1. 我用这100k条数据做k-fold交叉验证，来调模型参数</p><p>2. 我先随机划分出70k条数据做训练集用来根据交叉验证调参数，调好之后再用剩下的30k条数据做测试集</p><p>哪个思路是对的呢？</p></div>", "viewer": 9496, "tags": ["统计/机器学习", "模型验证"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>虽然这两个都没有错对之分，但是在数据量允许的情况下，更建议第2个思路。</p><p>对于思路1，如果你用交叉验证的预测误差作为模型的预测误差，这是有偏差的。因为交叉验证的误差通常是小于真实测试误差的。</p><p>思路2是我推荐的。因为你的测试集一定要和你的模型本身<span style=\"font-weight: bold;\">独立、无关</span>，测试集不能参与模型的训练。引申开来，还有第二层意思，你利用70k的数据训练完模型后，<span style=\"font-weight: bold;\">不能</span>根据在30k测试集上的表现再回去重新调整参数，因为一旦你这样做了，你就很可能会过拟合，你的交叉验证也就没有意义了。</p><p><br/></p></div>", "lvl2_answer": ["这回答，这头像，简直王之蔑视", "感谢！o_o\n看了@蓝色北方的回答，感觉我过去经常overfitting，因为我经常拿CV之后的测试集反复调试", "问得好，也答得好，很多人都以为有了cross validation就不用test set了"]}]}