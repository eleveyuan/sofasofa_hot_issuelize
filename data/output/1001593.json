{"id": "1001593", "question": "one class SVM到底是无监督还是有监督学习？", "description": "<div class=\"col-md-11 col-xs-10\"><p>One class SVM可以用来做异常点检测，到底是无监督还是有监督学习？或者是半监督？</p><p><br/></p></div>", "viewer": 12539, "tags": ["统计/机器学习", "监督式学习", "无监督学习", "半监督学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>虽然说是one class，但我感觉应该还是监督式学习，因为在训练时，你是知道所有的样本都是同一类的。</p><p>而非监督式学习时，你并不知道样本是否是一类或者几类。</p><p><br/></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>网上有说无监督，有说有监督的，也有人说是半监督的。</p><p>我觉得更像是有监督的。因为在one class svm里，你不会对训练集进行聚类，而是把训练集的样本全部标签当作已知的。</p><p>不过这个不重要吧，会用就行了。</p><p><br/></p></div>", "lvl2_answer": ["嗯嗯，对的，我只是好奇一下"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>我觉得用了kernel (RBF)的one class svm可用于无监督的clustering，把数据分为几个clusters，而linear one class svm可看作把空间分为两份，所有数据点在其中一半，相当于imbalanced two classes svm。但第二种情况估计没人用，所以可笼统的看作无监督。</p><p>再看一下two classes SVM的dual problem公式（来至wiki），</p><p><img data-filename=\"Unknown (1).png\" src=\"data:image/png;base64,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\" style=\"width: 452px;\"/><br/></p><p></p><p>其中$y$是$+1/-1$的标签，$x$是数据，$c$是数据点的重要性系数，$c&gt;0$的点是support vector。可以看到当$y_i=-1$时，$y_i*x_i=1*-x_i$，也就是把标签为$-1$的点$x_i$沿坐标原点对称得到$-x_i$，并当做标签为$1$的点。此时就是one class SVM，所有数据点在分割平面的一侧。</p><p>------------------------------------------------------------</p><p>当 one class SVM做异常点检查时应该是无监督的，因为不知道是否为异常点的标签。当求出分割边沿后，可以定义离边沿一定距离的点为异常点。</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>One-class SVM is used for novelty detection, that is, given a set of samples, it will detect the soft boundary of that set so as to classify new points as belonging to that set or not. The class that implements this is called OneClassSVM.</p><p>In this case, as it is a type of <b style=\"color: rgb(255, 0, 0);\">unsupervised</b> learning, the fit method will only take as input an array X, as there are no class labels.</p><p><a href=\"http://scikit-learn.org/stable/modules/svm.html#svm-outlier-detection\" target=\"_blank\">原文出处</a></p><p><br/><br/></p></div>", "lvl2_answer": []}]}