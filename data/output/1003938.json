{"id": "1003938", "question": "GBDT和XGBoost使用的都是回归树，原理上是怎么支持解决分类问题的？", "description": "<div class=\"col-md-11 col-xs-10\"><p>希望有大神从建树和损失函数的角度详细解释下。</p><p><br/></p></div>", "viewer": 9873, "tags": ["统计/机器学习", "监督式学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>GBDT和XGB一般是使用logloss作为损失函数。</p><p>建树的过程就是寻找最佳分叉点和分叉特征的过程。GBDT是用mse作为分叉和建树的标准。</p><p><a href=\"http://sofasofa.io/forum_main_post.php?postid=1000546\" target=\"_blank\">xgboost的损失函数可以参考这里</a>。</p></div>", "lvl2_answer": ["你对GBDT理解有问题。\nBoosting方法怎么可能使用分类树？分类树的结果怎么进行相加？", "和RF混淆了", "Boosting不能使用分类树？AdaBoost不就是分类树吗？"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>用softmax映射成概率，之后一样用(y - y_pred)来算残差。</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>GBDT使用的是回归树，而XGBoost除了回归树还支持其它线性分类器。如果使用回归树，那么返回的值也是连续的，我知道的是可以设定阈值thres来分类，当然可以根据你所分的区间进行分类。</p></div>", "lvl2_answer": []}]}