{"id": "1006182", "question": "关于tensorflow2的一点问题", "description": "<div class=\"col-md-11 col-xs-10\"><p>菜鸟想请教下gradienttape和optimizer的一些问题。做了一个二次函数的拟合</p><p>1.官方文档里面提到调用GradientTape.gradien()方法，就会释放GradientTapede拥有的资源，这个资源是指计算完的梯度么？</p><p>2.就是使用optimizer.apply_gradient()应用计算的梯度，并没有使用minimize()，这里怎么确保他是往损失minimize的方向呢？</p><p>3.对于方向传递，我进行GradientTape.gradien()计算梯度，我直接计算loss与第一层参数的梯度，可以使整体每层的参数得到更新，在backprop推导公式时都是一层一层的推导，可以理解为直接将loss与第一层参数进行连接求梯度，就能将内部参数全部更新么？</p><p><br/></p><pre><code class=\"python\">import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef add_layer(inputs, Weights, biases, activation_function=None):\n\n    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n    if activation_function is None:\n        outputs = Wx_plus_b\n    else:\n        outputs = activation_function(Wx_plus_b)\n    return outputs, Weights, biases\n\n\ndef loss(predicted_y, target_y):\n    return tf.math.reduce_mean(tf.math.square(predicted_y - target_y))\n\n\nx_data = np.linspace(-1, 1, 300)[:, np.newaxis]\nnoise = np.random.normal(0, 0.05, x_data.shape)\ny_data = np.square(x_data) - 0.5 + noise\nx_data = x_data.astype(np.float32)\nnoise = noise.astype(np.float32)\ny_data = y_data.astype(np.float32)\n\noptimizer = tf.optimizers.SGD(learning_rate=0.1)\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.scatter(x_data, y_data)\nplt.ion()\nplt.show()\n\nWl = tf.Variable(tf.random.normal((1, 10)))\nbl = tf.Variable(tf.zeros((1, 10)) + 0.1)\nWp = tf.Variable(tf.random.normal((10, 1)))\nbp = tf.Variable(tf.zeros((1, 1)) + 0.1)\n\nfor i in range(1000):\n    with tf.GradientTape() as tape:\n        l1, W1, b1 = add_layer(x_data, Wl, bl, activation_function=tf.nn.relu)\n        prediction, W2, b2 = add_layer(l1, Wp, bp, activation_function=None)\n        loss_val = loss(prediction, y_data)\n        print(loss_val)\n\n    grads = tape.gradient(loss_val, [W1, b1, W2, b2])  # 这里只适用W1,b1也能得到结果\n    optimizer.apply_gradients(zip(grads, [W1, b1, W2, b2]))\n    # print('W1: {},\\n b1{},\\n Wp: {},\\n bp: {}\\n\\n'.format(W1.numpy(), b1.numpy(), Wp.numpy(), bp.numpy()))\n    if i % 50 == 0:\n        try:\n            ax.lines.remove(lines[0])\n        except Exception:\n            pass\n        lines = ax.plot(x_data, prediction.numpy(), 'r-', lw=5)\n        plt.pause(0.1)</code></pre><p><br/></p><p><br/></p></div>", "viewer": 1376, "tags": ["统计/机器学习", "深度学习", "Python", "TensorFlow"], "answers": []}