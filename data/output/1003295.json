{"id": "1003295", "question": "为什么决策树中用熵而不是基尼不纯度来作为划分依据？", "description": "<div class=\"col-md-11 col-xs-10\"><p>决策树通常用熵而不是基尼不纯度来作为划分依据来选择特征，这是为什么？</p><p>熵和基尼不纯比有什么明显的优势呢？</p></div>", "viewer": 5059, "tags": ["统计/机器学习", "特征选择", "模型验证"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">熵和基尼相互之间从分类效果上说并没有所谓的优势和劣势，基尼计算起来有优势。</span></p><p><span style=\"font-size: 14px;\">有一篇对它们进行理论比较的文章</span><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.57.9764&amp;rep=rep1&amp;type=pdf\" target=\"_blank\"><span style=\"font-size: 14px;\">Theoretical Comparison between the Gini Index and Information Gain Criteria</span></a></p><p><span style=\"font-size: 14px;\">论文最后的结论是</span></p><p><span style=\"font-size: 14px;\">“We found\n </span><span style=\"font-size: 14px;\">that they disagree only in 2%, which explains why most previously published empirical results concluded that it is not  </span><span style=\"font-size: 14px;\">possible to decide which one of the two tests to prefer”</span></p><p><span style=\"font-size: 14px;\">只有2%的情况下，它们两个找到了不同的划分，这也解释了为什么过去的种种实验结果无法判断孰优孰劣了。</span></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>并不存在这样的说法。</p><p>决策树既可以用熵也可以用基尼，而且本来它们也是很接近的，$p_j$表示样本中标签$j$的占比，样本中一共有$m$中标签，那么</p><p>$$\\text{熵}=-\\sum_{i=1}^m p_j\\log p_j$$</p><p>$$\\text{基尼}=1-\\sum_{i=1}^m p^2_j$$</p><p>所以我们看出主要的区别就是基尼中把$\\log p_j$换成了$p_j$，相比于熵，基尼反而有计算量小的优势（不用算$\\log$）。</p></div>", "lvl2_answer": []}]}