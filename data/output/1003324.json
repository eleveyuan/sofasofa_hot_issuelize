{"id": "1003324", "question": "训练样本中每个维度是否独立对回归结果的影响", "description": "<div class=\"col-md-11 col-xs-10\"><p><span style=\"font-size: 18px;\">对于一个回归问题，使用最小二乘/岭回归/支持向量回归等回归方式，有一个样本的群用于训练，其中一个样本为$X_m=(Z_1,Z_2,\\cdots,Z_n,Y_m)$</span><i style=\"\"><span style=\"font-size: 18px;\">,</span></i><span style=\"font-size: 18px;\">    其中$(Z_1,Z_2,\\cdots,Z_n)$</span><span style=\"font-size: 18px;\">为</span><span style=\"font-size: 18px;\">$X_m$的输入，</span><span style=\"font-size: 18px;\">$Y_m$为输出。问题是，如果输入</span><span style=\"font-size: 18px;\">$Z_1,Z_2,\\cdots,Z_n$之间不是相互独立的，即输入向量的各维度之间有线性或非线性相关关系，这样训练得到的结果可信么？或者说，训练样本中各维度之间的独立性对回归结果的会有怎样的影响呢？</span></p></div>", "viewer": 5080, "tags": ["统计/机器学习", "回归分析", "特征选择", "开放问题"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>你说的这个叫做<a href=\"https://en.wikipedia.org/wiki/Multicollinearity\" target=\"_blank\">多重共线性</a>。一般可以用Pearson相关系数或者<a href=\"http://sofasofa.io/forum_main_post.php?postid=1000484\" target=\"_blank\">方差膨胀因子法</a>来检验。</p><p>对于最小二乘回归，多重共线性最直接的影响就是会导致$X^TX$不可逆，无法求解。</p><p>如果通过数值方法求解，得到的系数的解释性不会更好，而且方差会比较大。这一点对于你提到的模型算是共性。</p><p>在存在多重共线性的情况下，Lasso要比Ridge好。</p></div>", "lvl2_answer": ["谢谢！"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>最小二乘回归已经考虑了输入随机变量间相关的问题。令所有都为列向量，训练输入$X$是$d\\times n$矩阵，训练输出$y$是$1\\times n$，测试输入$X_{test}$是$d\\times m$矩阵。对$X$做SVD有$X=USV^T$。</p><p>$$\\hat{y_{test}}^T=X_{test}^T(XX^T)^{-1}Xy^T$$</p><p>$$=X_{test}^T(USV^TVSU^T)^{-1}Xy^T$$</p><p>$$=X_{test}^TUS^{-1} (X^TUS^{-1})^Ty^T$$</p><p>令$Z=S^{-1}U^TX=\\Phi X$，则</p><p>$$\\hat{y_{test}}^T=Z_{test}^TZy^T$$</p><p>$$=Z_{test}^T\\Sigma_{Zy}$$</p><p>$Z$是$X$在新特征空间（$X$ 的clomun space）的坐标，$U$是去相关性，$S^{-1}$是做$Z$的标准化。因为基向量$U_{i*}$与$U_{j*}$相互垂直，所以新特征$Z$相互独立，$corr(Z_i,Z_j)=0$。$\\Sigma_{Zy}$是最小二乘模型真正学习到的$Z$和$y$之间的相似矩阵，也就是$Z$和$y$之间的线性转化矩阵。</p><p>思路是：自变量相关，很难研究自变量$X$和因变量$y$间<span style=\"color: rgb(255, 0, 0);\">独立</span>线性关系。把自变量$X$转换为独立变量$Z$，并学习$Z$和$y$的线性转换关系$\\Sigma_{Zy}$。有点像输入图像-&gt;FFT-&gt;Filtering&gt;IFFT-&gt;输出图像的套路。（其实$X_i$和$y$的独立的相关性可以用<a href=\"https://en.wikipedia.org/wiki/Partial_correlation\" target=\"_blank\">partial correlation</a>表示。)</p></div>", "lvl2_answer": ["十分谢谢！"]}]}