{"id": "1002961", "question": "LR中若标签为+1和-1，损失函数如何推导，求大佬解答", "description": "<div class=\"col-md-11 col-xs-10\"><p>一般我们见到的都是0,1标签，+-1时该如何推导呢？</p></div>", "viewer": 7255, "tags": ["统计/机器学习", "回归分析", "监督式学习", "损失函数"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>logistic regression中用的是logistic sigmoid函数</p><p>$$\\text{sigmoid}(x)=\\frac{e^x}{e^x+1}\\in [0,1]$$</p><p>而$$\\text{tanh}(x)=2\\text{sigmoid}(2x)-1=\\frac{e^x-e^{-x}}{e^x+e^{-x}}\\in [-1,1]$$</p><p>下面蓝色是sigmoid，红色是tanh。</p><p><img data-filename=\"download (4).png\" src=\"data:image/png;base64,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\" style=\"width: 523.333px; height: 209.333px;\"/><br/></p><p></p><p>如果是用neural network，标签是一位的-1/+1，最后一层用tanh activation function。如果标签是一位的0/1，可用sigmoid。如果标签是多位的one hot编码，最后一层用softmax。</p><p>---------------------------------------------------------------------------------</p><p>令$x$是输入数据，$w$是logistic regression参数，$y=-1/1$是标签，$\\sigma(z)=\\sigma(w^Tx)$是sigmoid函数。</p><p>似然函数(likelihood)模型是</p><p>$P(y_i|x_i)_w=\\sigma(y_iz_i)$，$y_i=-1/1$, $z_i=w^Tx_i$</p><p>minimum negtive log likelihood可得损失函数：</p><p>$argmin_w{l(w)_{y,x}}$<br/></p><p>$=argmin_w{-\\sum_{i=1}^N ln\\sigma(y_iz_i)}$</p><p>$=argmin_w{\\sum_{i=1}^N ln\\dfrac{1}{\\sigma(y_iz_i)}}$</p><p>$=argmin_w{\\sum_{i=1}^N ln(1+e^{-y_iz_i})}$</p><p><br/></p><p>注意，因为用的模型是sigmoid函数，这里的最小负log释然函数等价于最小cross entropy。\n</p><p>如果用cross entropy写</p><p>令$t=0.5y+0.5$，表示是否$y==1$的标签，$t=0/1$。</p><p>$argmin_w{CE(w)_{y,x}}$</p><p>$=argmin_w{-[t_i ln\\sigma(z_i)+(1-t_i)ln(1-\\sigma(z_i))]}$</p><p>$=argmin_w{-[(0.5y+0.5)ln\\dfrac{1}{1+e^{-z_i}}+(0.5-0.5y)ln\\dfrac{1}{1+e^{z_i}}]}$</p><p>$=argmin_w{ln(1+e^{z_i})-\\dfrac{y+1}{2}z_i}$</p><p>当$y=-1/1$</p><p>$CE(w)_{y,x}=l(w)_{y,x}$</p><p><br/></p></div>", "lvl2_answer": ["虽然我也回答了，但是我更喜欢你的答案！", "老哥谢谢你的回答，不过我想知道的是最后推导出来的LR损失函数啊"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">为什么非要是-1和+1呢？把0，1映射成-1，+1不就可以了？</span></p><p><span style=\"font-size: 14px;\">逻辑回归里通常把负样本标记为0其实是有意义的，因为逻辑回归可以得到预测概率，预测结果为0，不仅表示了是负样本，同时也是表示$P(Y=1)=0$的意思。-1，+1表达不了这个。</span></p></div>", "lvl2_answer": ["我也是看到有个面试题这么问的==", "那就做映射好了，把原来的$y$换成$2y-1$"]}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>建议你看林轩田老师的 机器学习基石 的第十课的ppt，里面就有推导</p></div>", "lvl2_answer": []}]}