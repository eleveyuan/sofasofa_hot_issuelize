{"id": "1003228", "question": "为什么神经网络模型不用交叉验证？", "description": "<div class=\"col-md-11 col-xs-10\"><p>最近开始自学神经网络，深度学习，看了网上不少教程，发现通常只是把数据集分成train set和eval set，很少做交叉验证的。</p><p>为什么我们不对神经网络模型进行交叉验证呢？有什么原因吗？</p></div>", "viewer": 10006, "tags": ["统计/机器学习", "深度学习", "模型验证", "人工神经网络"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">当然可以对neural netwok进行cross validation，但是有时候我们并不这么做，我们只做train validation split。</span></p><p><span style=\"font-size: 14px;\">理由是：</span></p><p><span style=\"font-size: 14px;\">1. 训练神经网络的计算代价很大，k-fold cv则需要训练k个神经网络</span></p><p><span style=\"font-size: 14px;\">2. 在用神经网络时，我们往往有极大量的数据，在这种情况下，我们没有必要去通过cross validation来充分利用数据</span></p><p><span style=\"font-size: 14px;\">如果有说的不对的地方，欢迎指正</span></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>也不是完全不用交叉验证，只是用的话比较慢吧</p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>如果用了dropout，相当于用了cross validation，因为每个训练数据在每个epoch只能见到一个随机的子网络。最后测试时是这k个子网络的平均，k接近无限。</p><p>还有如果随机的组成mini batch，每个batch又是训练数据的随机子集，也相当于把训练数据分为无限个子集，降低了过拟合风险。</p><p>我理解是以上两点引入足够的随机性，能让结果稳定。如果还有过拟合，还可以加其他方法，比如对参数加L1/L2norm限制，data augmentation，unet/auto encoder等稀疏结构。</p></div>", "lvl2_answer": []}]}