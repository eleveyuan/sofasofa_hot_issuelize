{"id": "1007447", "question": "机器学习中的维度灾难怎么防止和克服？", "description": "<div class=\"col-md-11 col-xs-10\"><p>机器学习中的维度灾难怎么防止和克服？</p></div>", "viewer": 2262, "tags": ["统计/机器学习", "数据预处理"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>如果n是样本数量，p是数据的维度，当p非常大，或者p远大于n的时候，数据建模问题会变得非常棘手，这个现象就叫做维度灾难(curse of dimensionality)。</p><p>总之我们就是要防止p太大了。p在两种情况下会太大：</p><p>（1）本来p就很大；（2）经过预处理后p变得很大。</p><p>对于（1），我们要使用降维的方法来减小p，常见的方法可以参考<a href=\"http://sofasofa.io/forum_main_post.php?postid=1000442\" target=\"_blank\">除了PCA，还有什么降维的方法？</a></p><p>对于（2），我们要对预处理的过程小心谨慎，尽量不要创造出太多冗余的、无用的特征出来，比较容易出问题的是当我们对一个level很多的categorical feature做one-hot处理时，会有很多的稀疏特征产生，这时候容易造成维度灾难，所以要注意取舍和降维。</p></div>", "lvl2_answer": []}]}