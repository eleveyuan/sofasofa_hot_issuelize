{"id": "1003957", "question": "坐标下降法和最小角回归求取L1范数正则化问题时的优劣？", "description": "<div class=\"col-md-11 col-xs-10\"><p>坐标下降法和最小角回归（经过修正）都能用于处理L1范数正则化的问题，那么这两个方法在计算效率上哪个更高呢？</p><p>另外，由于严格意义上坐标下降法对于不可微的凸函数是不一定能获得全局最优解的，在这个意义上来说，是不是说利用坐标下降法求解L1范数正则化问题得到的结果相较于最小角回归得到的结果可信度更不高呢？</p></div>", "viewer": 3414, "tags": ["统计/机器学习", "回归分析", "监督式学习", "开放问题"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>从工程地角度说，sklearn里的LASSO默认是用坐标下降法。<a href=\"https://scikit-learn.org/stable/modules/linear_model.html#lasso\" target=\"_blank\">官方文档看这里。</a>我猜测是坐标下降更快。</p><p>但是sklearn也提供了基于最小角回归的实现。</p><p>你可以自己比较一下：<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso\" target=\"_blank\">sklearn.linear_model.Lasso</a>和<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lars.html#sklearn.linear_model.Lars\" target=\"_blank\">sklearn.linear_model.Lars</a></p></div>", "lvl2_answer": ["多谢多谢"]}]}