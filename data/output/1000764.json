{"id": "1000764", "question": "欠采样后概率还原问题", "description": "<div class=\"col-md-11 col-xs-10\"><p>我有个非平衡的二元分类问题，0和1的比例是1比7左右。因为数据量不少，所以我对1进行了欠采样，随机取了1/7的1。</p><p>欠采样之后，0和1的比例基本上就是1:1了。问题是，根据这个样本进行训练的模型，作用在测试集上，测试集的概率都偏大了，按道理概率的平均值是0.125，结果是0.5。这个应该是和欠采样有关的。</p><p>有什么办法对这个进行修正吗？</p></div>", "viewer": 7800, "tags": ["统计/机器学习", "监督式学习"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>这个问题一直没有人回答，我来说说吧。</p><p>假设负样本非常多，正样本非常少。于是我们训练时保留了全部的正样本，但是对负样本进行了欠采样，比如说我们只用了$\\beta$比例的负样本，$0\\lt \\beta\\lt 1$。假设$X$样本在欠采样之后，被预测为正样本的概率为$p_s$，那么修正后的概率为</p><p>$$p=\\frac{p_s\\beta}{p_s\\beta-p_s+1}$$</p><p>比如说，原来正负比例为1：10，欠采样的$\\beta$为0.2，也就是说20%的负样本被选中。欠采样之后，正负比例为1：2，样本$X$被预测为正的概率为$p_s=0.5$，那么</p><p>$$p=\\frac{p_s\\beta}{p_s\\beta-p_s+1}=\\frac{0.5\\cdot 0.2}{0.5\\cdot 0.2-0.5+1}\\approx 0.183$$</p><p><br/></p><p>参考文献：</p><p><a href=\"https://www3.nd.edu/~rjohns15/content/papers/ssci2015_calibrating.pdf\" target=\"_blank\">Calibrating Probability with Undersampling for Unbalanced Classification. A.D. Pozzolo, et al.</a><br/></p></div>", "lvl2_answer": []}, {"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p><span style=\"font-size: 14px;\">令$X$为输入数据，$Y$为原始标签，$Y'$为数据平衡（subsample/oversample）后的标签，</span><span style=\"font-size: 14px;\">$P(X|Y)$为模型得到的释然函数，$P(Y)$为0/1类概率的</span><span style=\"font-size: 14px;\">先验知识。默认释然函数在数据平衡前后是一致的，$P(X|Y)=P(X|Y')$</span></p><p><span style=\"font-size: 14px;\">根据贝叶斯， $P(Y|X)=\\dfrac{P(X|Y)P(Y)}{P(X)} =P(X|Y)P(Y)\\frac{1}{Z}$，这里$P(X)=Z$是一常数，一般忽略。</span></p><p><span style=\"font-size: 14px;\">做完数据平衡后, $P(Y'=1)=P(Y'=0)=0.5$，模型输出（比如logistic regression）为标签1的概率$p_s$</span></p><p><span style=\"font-size: 14px;\">$$p_s=P(Y'=1|X)=P(X|Y'=1)P(Y'=1)$$。</span></p><p><span style=\"font-size: 14px;\">做完数据平衡前$P(Y=1)/P(Y=0)=\\beta$，假设标签1的样本更少，$\\beta \\in [0,1)$。我们想要知道的原始数据得到的为标签0/1的概率$p_0,p_1$</span></p><p><span style=\"font-size: 14px;\">$$p_1=P(Y=1|X)=P(X|Y=1)P(Y=1)=\\dfrac{P(Y'=1|X)}{P(Y'=1)}P(Y=1)=2p_sP(Y=1)$$</span></p><p><span style=\"font-size: 14px;\">$$p_0=P(Y=0|X)=P(X|Y=0)P(Y=0)=\\dfrac{1-P(Y'=1|X)}{P(Y'=0)}P(Y=0)=2(1-p_s)P(Y=0)$$</span></p><p><span style=\"font-size: 14px;\">对上面两式做归一化，得原始标签为1的概率</span></p><p><span style=\"font-size: 14px;\">$$p=\\dfrac{p_1}{p_1+p_0}$$</span></p><p><span style=\"font-size: 14px;\">$$=\\dfrac{2p_sP(Y=1)}{2p_sP(Y=1)+2(1-p_s)P(Y=0)}$$</span></p><p><span style=\"font-size: 14px;\">$$=\\dfrac{p_s\\beta}{p_s\\beta+1-p_s}$$</span></p><p><span style=\"font-size: 14px;\">结论：关键的思想是释然函数只和模型相关，和数据无关。对数据subsample或oversample，只会影响先验概率$P(Y)$。以释然函数为桥，通过平衡后的后验概率$p_s$得到释然函数$P(Y=1|X)$，然后由释然函数再得平衡前的后验概率$p$。</span></p><p><a href=\"http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance/\" target=\"_blank\"><span style=\"font-size: 14px;\">这里</span></a><span style=\"font-size: 14px;\">对这种先数据平衡再对后验概率做修正的方法提出疑问。结论是用SVM更好。</span></p><p><a href=\"https://www3.nd.edu/~rwilliam/stats3/rareevents.pdf\" target=\"_blank\"><span style=\"font-size: 14px;\">这个总结</span></a><span style=\"font-size: 14px;\">提到，如果用logistic regression。有两种方法。</span></p><p><span style=\"font-size: 14px;\">1.Bias Correction method</span></p><p><span style=\"font-size: 14px;\">2.Penalized Maximum Likelihood Estimation， Firth method</span></p></div>", "lvl2_answer": []}]}