{"id": "1002662", "question": "在random forest和xgboost这类集成树模型中是如何计算_feature_importance的", "description": "<div class=\"col-md-11 col-xs-10\">大概觉得和某特征作为切分点使用的频度有关，但是对具体的算法很迷糊。</div>", "viewer": 8506, "tags": ["统计/机器学习", "监督式学习", "特征选择"], "answers": [{"lvl1_answer": "<div class=\"col-md-11 col-xs-10 p-r\"><p>随机森林和xgboost中的importance是一样的计算方法。</p><p><br/></p><p>概括地说，一棵树中，某个特征的importance就是损失函数在这个特征切分点上的提升。在整个模型中，importance就是它在所有树上importance的均值。</p><p>例如，对于一个二元分类问题，我们用了gini impurity作为分叉标准的随机森林。假设，森林中一共三棵树。</p><p>特征A在树1中作为划分点，并且在这个点上，gini从0.6降到0.3。</p><p>特征A在树2中作为划分点，并且在这个点上，gini从0.5降到0.4。</p><p>特征A并没有出现在树3中。</p><p>特征A的importance为：((0.6-0.3)+(0.5-0.4))/3=0.13</p><p>特征B在树1中作为划分点，并且在这个点上，gini从0.3降到0.1。\n</p><p>特征B在树2中作为划分点，并且在这个点上，gini从0.7降到0.5。\n</p><p>\n特征B在树3中作为划分点，并且在这个点上，gini从0.4降到0.1。\n</p><p>特征B的importance为：((0.3-0.1)+(0.7-0.5)+(0.4-0.1))/3=0.23</p><p><br/></p><p>上面的例子是gini，当然也可以entropy。对于回归任务来说，损失函数可以是MSE，或者MAE之类。</p><p><br/></p></div>", "lvl2_answer": ["非常清晰，感谢！", "赞！"]}]}